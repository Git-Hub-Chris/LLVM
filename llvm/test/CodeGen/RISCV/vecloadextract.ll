; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv32 -target-abi=ilp32d -mattr=+m,+f,+d,+zfh -verify-machineinstrs < %s | FileCheck %s --check-prefixes=CHECK,RV32,RV32NOV
; RUN: llc -mtriple=riscv32 -target-abi=ilp32d -mattr=+v,+m,+f,+d,+zfh,+zvfh -verify-machineinstrs < %s | FileCheck %s --check-prefixes=CHECK,RV32,RV32V
; RUN: llc -mtriple=riscv64 -target-abi=lp64d -mattr=+m,+f,+d,+zfh -verify-machineinstrs < %s | FileCheck %s --check-prefixes=CHECK,RV64,RV64NOV
; RUN: llc -mtriple=riscv64 -target-abi=lp64d -mattr=+v,+m,+f,+d,+zfh,+zvfh -verify-machineinstrs < %s | FileCheck %s --check-prefixes=CHECK,RV64,RV64V

; This test copy from x86.

define i32 @const_index(ptr %v) {
; CHECK-LABEL: const_index:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lw a0, 4(a0)
; CHECK-NEXT:    ret
  %a = load <8 x i32>, ptr %v
  %b = extractelement <8 x i32> %a, i32 1
  ret i32 %b
}

define i32 @variable_index(ptr %v, i32 %i) {
; RV32-LABEL: variable_index:
; RV32:       # %bb.0:
; RV32-NEXT:    andi a1, a1, 7
; RV32-NEXT:    slli a1, a1, 2
; RV32-NEXT:    add a0, a0, a1
; RV32-NEXT:    lw a0, 0(a0)
; RV32-NEXT:    ret
;
; RV64NOV-LABEL: variable_index:
; RV64NOV:       # %bb.0:
; RV64NOV-NEXT:    addi sp, sp, -32
; RV64NOV-NEXT:    .cfi_def_cfa_offset 32
; RV64NOV-NEXT:    lw a2, 0(a0)
; RV64NOV-NEXT:    lw a3, 4(a0)
; RV64NOV-NEXT:    lw a4, 8(a0)
; RV64NOV-NEXT:    lw a5, 12(a0)
; RV64NOV-NEXT:    lw a6, 28(a0)
; RV64NOV-NEXT:    lw a7, 24(a0)
; RV64NOV-NEXT:    lw t0, 20(a0)
; RV64NOV-NEXT:    lw a0, 16(a0)
; RV64NOV-NEXT:    sw a6, 28(sp)
; RV64NOV-NEXT:    sw a7, 24(sp)
; RV64NOV-NEXT:    sw t0, 20(sp)
; RV64NOV-NEXT:    sw a0, 16(sp)
; RV64NOV-NEXT:    sw a5, 12(sp)
; RV64NOV-NEXT:    sw a4, 8(sp)
; RV64NOV-NEXT:    sw a3, 4(sp)
; RV64NOV-NEXT:    sw a2, 0(sp)
; RV64NOV-NEXT:    andi a1, a1, 7
; RV64NOV-NEXT:    slli a1, a1, 2
; RV64NOV-NEXT:    mv a0, sp
; RV64NOV-NEXT:    add a0, a0, a1
; RV64NOV-NEXT:    lw a0, 0(a0)
; RV64NOV-NEXT:    addi sp, sp, 32
; RV64NOV-NEXT:    ret
;
; RV64V-LABEL: variable_index:
; RV64V:       # %bb.0:
; RV64V-NEXT:    vsetivli zero, 8, e32, m2, ta, ma
; RV64V-NEXT:    vle32.v v8, (a0)
; RV64V-NEXT:    slli a1, a1, 32
; RV64V-NEXT:    srli a1, a1, 32
; RV64V-NEXT:    vsetivli zero, 1, e32, m2, ta, ma
; RV64V-NEXT:    vslidedown.vx v8, v8, a1
; RV64V-NEXT:    vmv.x.s a0, v8
; RV64V-NEXT:    ret
  %a = load <8 x i32>, ptr %v
  %b = extractelement <8 x i32> %a, i32 %i
  ret i32 %b
}

define i32 @variable_index_with_addrspace(ptr addrspace(1) %v, i32 %i) {
; RV32-LABEL: variable_index_with_addrspace:
; RV32:       # %bb.0:
; RV32-NEXT:    andi a1, a1, 7
; RV32-NEXT:    slli a1, a1, 2
; RV32-NEXT:    add a0, a0, a1
; RV32-NEXT:    lw a0, 0(a0)
; RV32-NEXT:    ret
;
; RV64NOV-LABEL: variable_index_with_addrspace:
; RV64NOV:       # %bb.0:
; RV64NOV-NEXT:    addi sp, sp, -32
; RV64NOV-NEXT:    .cfi_def_cfa_offset 32
; RV64NOV-NEXT:    lw a2, 0(a0)
; RV64NOV-NEXT:    lw a3, 4(a0)
; RV64NOV-NEXT:    lw a4, 8(a0)
; RV64NOV-NEXT:    lw a5, 12(a0)
; RV64NOV-NEXT:    lw a6, 28(a0)
; RV64NOV-NEXT:    lw a7, 24(a0)
; RV64NOV-NEXT:    lw t0, 20(a0)
; RV64NOV-NEXT:    lw a0, 16(a0)
; RV64NOV-NEXT:    sw a6, 28(sp)
; RV64NOV-NEXT:    sw a7, 24(sp)
; RV64NOV-NEXT:    sw t0, 20(sp)
; RV64NOV-NEXT:    sw a0, 16(sp)
; RV64NOV-NEXT:    sw a5, 12(sp)
; RV64NOV-NEXT:    sw a4, 8(sp)
; RV64NOV-NEXT:    sw a3, 4(sp)
; RV64NOV-NEXT:    sw a2, 0(sp)
; RV64NOV-NEXT:    andi a1, a1, 7
; RV64NOV-NEXT:    slli a1, a1, 2
; RV64NOV-NEXT:    mv a0, sp
; RV64NOV-NEXT:    add a0, a0, a1
; RV64NOV-NEXT:    lw a0, 0(a0)
; RV64NOV-NEXT:    addi sp, sp, 32
; RV64NOV-NEXT:    ret
;
; RV64V-LABEL: variable_index_with_addrspace:
; RV64V:       # %bb.0:
; RV64V-NEXT:    vsetivli zero, 8, e32, m2, ta, ma
; RV64V-NEXT:    vle32.v v8, (a0)
; RV64V-NEXT:    slli a1, a1, 32
; RV64V-NEXT:    srli a1, a1, 32
; RV64V-NEXT:    vsetivli zero, 1, e32, m2, ta, ma
; RV64V-NEXT:    vslidedown.vx v8, v8, a1
; RV64V-NEXT:    vmv.x.s a0, v8
; RV64V-NEXT:    ret
  %a = load <8 x i32>, ptr addrspace(1) %v
  %b = extractelement <8 x i32> %a, i32 %i
  ret i32 %b
}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; RV32NOV: {{.*}}
; RV32V: {{.*}}
; RV64: {{.*}}
