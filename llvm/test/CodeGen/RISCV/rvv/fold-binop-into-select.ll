; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc -mtriple=riscv32 -mattr=+v -verify-machineinstrs < %s | FileCheck -check-prefixes=CHECK,RV32 %s
; RUN: llc -mtriple=riscv64 -mattr=+v -verify-machineinstrs < %s | FileCheck -check-prefixes=CHECK,RV64 %s

; The following binop x, (zext i1) tests will be vector-legalized into a vselect
; of two splat_vectors, but on RV64 the splat value will be implicitly
; truncated:
;
;       t15: nxv2i32 = splat_vector Constant:i64<1>
;       t13: nxv2i32 = splat_vector Constant:i64<0>
;     t16: nxv2i32 = vselect t2, t15, t13
;   t7: nxv2i32 = add t4, t16
;
; Make sure that foldSelectWithIdentityConstant in DAGCombiner.cpp handles the
; truncating splat, so we pull the vselect back and fold it into a mask.

define <vscale x 2 x i32> @i1_zext_add(<vscale x 2 x i1> %a, <vscale x 2 x i32> %b) {
; RV32-LABEL: i1_zext_add:
; RV32:       # %bb.0:
; RV32-NEXT:    vsetvli a0, zero, e32, m1, ta, mu
; RV32-NEXT:    vadd.vi v8, v8, 1, v0.t
; RV32-NEXT:    ret
;
; RV64-LABEL: i1_zext_add:
; RV64:       # %bb.0:
; RV64-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; RV64-NEXT:    vmv.v.i v9, 0
; RV64-NEXT:    vmerge.vim v9, v9, 1, v0
; RV64-NEXT:    vadd.vv v8, v8, v9
; RV64-NEXT:    ret
  %zext = zext <vscale x 2 x i1> %a to <vscale x 2 x i32>
  %add = add <vscale x 2 x i32> %b, %zext
  ret <vscale x 2 x i32> %add
}

define <vscale x 2 x i32> @i1_zext_add_commuted(<vscale x 2 x i1> %a, <vscale x 2 x i32> %b) {
; RV32-LABEL: i1_zext_add_commuted:
; RV32:       # %bb.0:
; RV32-NEXT:    vsetvli a0, zero, e32, m1, ta, mu
; RV32-NEXT:    vadd.vi v8, v8, 1, v0.t
; RV32-NEXT:    ret
;
; RV64-LABEL: i1_zext_add_commuted:
; RV64:       # %bb.0:
; RV64-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; RV64-NEXT:    vmv.v.i v9, 0
; RV64-NEXT:    vmerge.vim v9, v9, 1, v0
; RV64-NEXT:    vadd.vv v8, v9, v8
; RV64-NEXT:    ret
  %zext = zext <vscale x 2 x i1> %a to <vscale x 2 x i32>
  %add = add <vscale x 2 x i32> %zext, %b
  ret <vscale x 2 x i32> %add
}

define <vscale x 2 x i32> @i1_zext_sub(<vscale x 2 x i1> %a, <vscale x 2 x i32> %b) {
; RV32-LABEL: i1_zext_sub:
; RV32:       # %bb.0:
; RV32-NEXT:    li a0, 1
; RV32-NEXT:    vsetvli a1, zero, e32, m1, ta, mu
; RV32-NEXT:    vsub.vx v8, v8, a0, v0.t
; RV32-NEXT:    ret
;
; RV64-LABEL: i1_zext_sub:
; RV64:       # %bb.0:
; RV64-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; RV64-NEXT:    vmv.v.i v9, 0
; RV64-NEXT:    vmerge.vim v9, v9, 1, v0
; RV64-NEXT:    vsub.vv v8, v8, v9
; RV64-NEXT:    ret
  %zext = zext <vscale x 2 x i1> %a to <vscale x 2 x i32>
  %sub = sub <vscale x 2 x i32> %b, %zext
  ret <vscale x 2 x i32> %sub
}

define <vscale x 2 x i32> @i1_zext_or(<vscale x 2 x i1> %a, <vscale x 2 x i32> %b) {
; RV32-LABEL: i1_zext_or:
; RV32:       # %bb.0:
; RV32-NEXT:    vsetvli a0, zero, e32, m1, ta, mu
; RV32-NEXT:    vor.vi v8, v8, 1, v0.t
; RV32-NEXT:    ret
;
; RV64-LABEL: i1_zext_or:
; RV64:       # %bb.0:
; RV64-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; RV64-NEXT:    vmv.v.i v9, 0
; RV64-NEXT:    vmerge.vim v9, v9, 1, v0
; RV64-NEXT:    vor.vv v8, v8, v9
; RV64-NEXT:    ret
  %zext = zext <vscale x 2 x i1> %a to <vscale x 2 x i32>
  %or = or <vscale x 2 x i32> %b, %zext
  ret <vscale x 2 x i32> %or
}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; CHECK: {{.*}}
