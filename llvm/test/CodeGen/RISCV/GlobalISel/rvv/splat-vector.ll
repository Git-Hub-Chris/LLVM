; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=riscv32 -mattr=+v,+zvfh -global-isel \
; RUN:   -verify-machineinstrs < %s | FileCheck -check-prefixes=CHECK,RV32 %s
; RUN: llc -mtriple=riscv64 -mattr=+v,+zvfh -global-isel \
; RUN:   -verify-machineinstrs < %s | FileCheck -check-prefixes=CHECK,RV64 %s

define <vscale x 1 x i1> @splat_zero_nxv1i1() {
; CHECK-LABEL: splat_zero_nxv1i1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, mf8, ta, ma
; CHECK-NEXT:    vmclr.m v0
; CHECK-NEXT:    ret
  ret <vscale x 1 x i1> zeroinitializer
}

define <vscale x 2 x i1> @splat_zero_nxv2i1() {
; CHECK-LABEL: splat_zero_nxv2i1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, mf4, ta, ma
; CHECK-NEXT:    vmclr.m v0
; CHECK-NEXT:    ret
  ret <vscale x 2 x i1> zeroinitializer
}

define <vscale x 4 x i1> @splat_zero_nxv4i1() {
; CHECK-LABEL: splat_zero_nxv4i1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, mf2, ta, ma
; CHECK-NEXT:    vmclr.m v0
; CHECK-NEXT:    ret
  ret <vscale x 4 x i1> zeroinitializer
}

define <vscale x 8 x i1> @splat_zero_nxv8i1() {
; CHECK-LABEL: splat_zero_nxv8i1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmclr.m v0
; CHECK-NEXT:    ret
  ret <vscale x 8 x i1> zeroinitializer
}

define <vscale x 16 x i1> @splat_zero_nxv16i1() {
; CHECK-LABEL: splat_zero_nxv16i1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m2, ta, ma
; CHECK-NEXT:    vmclr.m v0
; CHECK-NEXT:    ret
  ret <vscale x 16 x i1> zeroinitializer
}

define <vscale x 32 x i1> @splat_zero_nxv32i1() {
; CHECK-LABEL: splat_zero_nxv32i1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m4, ta, ma
; CHECK-NEXT:    vmclr.m v0
; CHECK-NEXT:    ret
  ret <vscale x 32 x i1> zeroinitializer
}

define <vscale x 64 x i1> @splat_zero_nxv64i1() {
; CHECK-LABEL: splat_zero_nxv64i1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m8, ta, ma
; CHECK-NEXT:    vmclr.m v0
; CHECK-NEXT:    ret
  ret <vscale x 64 x i1> zeroinitializer
}

define <vscale x 1 x i8> @splat_zero_nxv1i8() {
; CHECK-LABEL: splat_zero_nxv1i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, mf8, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 1 x i8> zeroinitializer
}

define <vscale x 2 x i8> @splat_zero_nxv2i8() {
; CHECK-LABEL: splat_zero_nxv2i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, mf4, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 2 x i8> zeroinitializer
}

define <vscale x 4 x i8> @splat_zero_nxv4i8() {
; CHECK-LABEL: splat_zero_nxv4i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, mf2, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 4 x i8> zeroinitializer
}

define <vscale x 8 x i8> @splat_zero_nxv8i8() {
; CHECK-LABEL: splat_zero_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 8 x i8> zeroinitializer
}

define <vscale x 16 x i8> @splat_zero_nxv16i8() {
; CHECK-LABEL: splat_zero_nxv16i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m2, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 16 x i8> zeroinitializer
}

define <vscale x 32 x i8> @splat_zero_nxv32i8() {
; CHECK-LABEL: splat_zero_nxv32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m4, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 32 x i8> zeroinitializer
}

define <vscale x 64 x i8> @splat_zero_nxv64i8() {
; CHECK-LABEL: splat_zero_nxv64i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m8, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 64 x i8> zeroinitializer
}

define <vscale x 1 x i16> @splat_zero_nxv1i16() {
; CHECK-LABEL: splat_zero_nxv1i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, mf4, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 1 x i16> zeroinitializer
}

define <vscale x 2 x i16> @splat_zero_nxv2i16() {
; CHECK-LABEL: splat_zero_nxv2i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, mf2, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 2 x i16> zeroinitializer
}

define <vscale x 4 x i16> @splat_zero_nxv4i16() {
; CHECK-LABEL: splat_zero_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 4 x i16> zeroinitializer
}

define <vscale x 8 x i16> @splat_zero_nxv8i16() {
; CHECK-LABEL: splat_zero_nxv8i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, m2, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 8 x i16> zeroinitializer
}

define <vscale x 16 x i16> @splat_zero_nxv16i16() {
; CHECK-LABEL: splat_zero_nxv16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, m4, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 16 x i16> zeroinitializer
}

define <vscale x 32 x i16> @splat_zero_nxv32i16() {
; CHECK-LABEL: splat_zero_nxv32i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, m8, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 32 x i16> zeroinitializer
}

define <vscale x 1 x i32> @splat_zero_nxv1i32() {
; CHECK-LABEL: splat_zero_nxv1i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e32, mf2, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 1 x i32> zeroinitializer
}

define <vscale x 2 x i32> @splat_zero_nxv2i32() {
; CHECK-LABEL: splat_zero_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 2 x i32> zeroinitializer
}

define <vscale x 4 x i32> @splat_zero_nxv4i32() {
; CHECK-LABEL: splat_zero_nxv4i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e32, m2, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 4 x i32> zeroinitializer
}

define <vscale x 8 x i32> @splat_zero_nxv8i32() {
; CHECK-LABEL: splat_zero_nxv8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e32, m4, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 8 x i32> zeroinitializer
}

define <vscale x 16 x i32> @splat_zero_nxv16i32() {
; CHECK-LABEL: splat_zero_nxv16i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e32, m8, ta, ma
; CHECK-NEXT:    vmv.v.x v8, zero
; CHECK-NEXT:    ret
  ret <vscale x 16 x i32> zeroinitializer
}

define <vscale x 1 x i64> @splat_zero_nxv1i64() {
; RV32-LABEL: splat_zero_nxv1i64:
; RV32:       # %bb.0:
; RV32-NEXT:    addi sp, sp, -16
; RV32-NEXT:    .cfi_def_cfa_offset 16
; RV32-NEXT:    sw zero, 8(sp)
; RV32-NEXT:    sw zero, 12(sp)
; RV32-NEXT:    fld fa5, 8(sp)
; RV32-NEXT:    vsetvli a0, zero, e64, m1, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    addi sp, sp, 16
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv1i64:
; RV64:       # %bb.0:
; RV64-NEXT:    vsetvli a0, zero, e64, m1, ta, ma
; RV64-NEXT:    vmv.v.x v8, zero
; RV64-NEXT:    ret
  ret <vscale x 1 x i64> zeroinitializer
}

define <vscale x 2 x i64> @splat_zero_nxv2i64() {
; RV32-LABEL: splat_zero_nxv2i64:
; RV32:       # %bb.0:
; RV32-NEXT:    addi sp, sp, -16
; RV32-NEXT:    .cfi_def_cfa_offset 16
; RV32-NEXT:    sw zero, 8(sp)
; RV32-NEXT:    sw zero, 12(sp)
; RV32-NEXT:    fld fa5, 8(sp)
; RV32-NEXT:    vsetvli a0, zero, e64, m2, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    addi sp, sp, 16
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv2i64:
; RV64:       # %bb.0:
; RV64-NEXT:    vsetvli a0, zero, e64, m2, ta, ma
; RV64-NEXT:    vmv.v.x v8, zero
; RV64-NEXT:    ret
  ret <vscale x 2 x i64> zeroinitializer
}

define <vscale x 4 x i64> @splat_zero_nxv4i64() {
; RV32-LABEL: splat_zero_nxv4i64:
; RV32:       # %bb.0:
; RV32-NEXT:    addi sp, sp, -16
; RV32-NEXT:    .cfi_def_cfa_offset 16
; RV32-NEXT:    sw zero, 8(sp)
; RV32-NEXT:    sw zero, 12(sp)
; RV32-NEXT:    fld fa5, 8(sp)
; RV32-NEXT:    vsetvli a0, zero, e64, m4, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    addi sp, sp, 16
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv4i64:
; RV64:       # %bb.0:
; RV64-NEXT:    vsetvli a0, zero, e64, m4, ta, ma
; RV64-NEXT:    vmv.v.x v8, zero
; RV64-NEXT:    ret
  ret <vscale x 4 x i64> zeroinitializer
}

define <vscale x 8 x i64> @splat_zero_nxv8i64() {
; RV32-LABEL: splat_zero_nxv8i64:
; RV32:       # %bb.0:
; RV32-NEXT:    addi sp, sp, -16
; RV32-NEXT:    .cfi_def_cfa_offset 16
; RV32-NEXT:    sw zero, 8(sp)
; RV32-NEXT:    sw zero, 12(sp)
; RV32-NEXT:    fld fa5, 8(sp)
; RV32-NEXT:    vsetvli a0, zero, e64, m8, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    addi sp, sp, 16
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv8i64:
; RV64:       # %bb.0:
; RV64-NEXT:    vsetvli a0, zero, e64, m8, ta, ma
; RV64-NEXT:    vmv.v.x v8, zero
; RV64-NEXT:    ret
  ret <vscale x 8 x i64> zeroinitializer
}

define <vscale x 1 x float> @splat_zero_nxv1f32() {
; RV32-LABEL: splat_zero_nxv1f32:
; RV32:       # %bb.0:
; RV32-NEXT:    fmv.w.x fa5, zero
; RV32-NEXT:    vsetvli a0, zero, e32, mf2, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv1f32:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.w.x fa5, zero
; RV64-NEXT:    fmv.x.w a0, fa5
; RV64-NEXT:    vsetvli a1, zero, e32, mf2, ta, ma
; RV64-NEXT:    vmv.v.x v8, a0
; RV64-NEXT:    ret
  ret <vscale x 1 x float> zeroinitializer
}

define <vscale x 2 x float> @splat_zero_nxv2f32() {
; RV32-LABEL: splat_zero_nxv2f32:
; RV32:       # %bb.0:
; RV32-NEXT:    fmv.w.x fa5, zero
; RV32-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv2f32:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.w.x fa5, zero
; RV64-NEXT:    fmv.x.w a0, fa5
; RV64-NEXT:    vsetvli a1, zero, e32, m1, ta, ma
; RV64-NEXT:    vmv.v.x v8, a0
; RV64-NEXT:    ret
  ret <vscale x 2 x float> zeroinitializer
}

define <vscale x 4 x float> @splat_zero_nxv4f32() {
; RV32-LABEL: splat_zero_nxv4f32:
; RV32:       # %bb.0:
; RV32-NEXT:    fmv.w.x fa5, zero
; RV32-NEXT:    vsetvli a0, zero, e32, m2, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv4f32:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.w.x fa5, zero
; RV64-NEXT:    fmv.x.w a0, fa5
; RV64-NEXT:    vsetvli a1, zero, e32, m2, ta, ma
; RV64-NEXT:    vmv.v.x v8, a0
; RV64-NEXT:    ret
  ret <vscale x 4 x float> zeroinitializer
}

define <vscale x 8 x float> @splat_zero_nxv8f32() {
; RV32-LABEL: splat_zero_nxv8f32:
; RV32:       # %bb.0:
; RV32-NEXT:    fmv.w.x fa5, zero
; RV32-NEXT:    vsetvli a0, zero, e32, m4, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv8f32:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.w.x fa5, zero
; RV64-NEXT:    fmv.x.w a0, fa5
; RV64-NEXT:    vsetvli a1, zero, e32, m4, ta, ma
; RV64-NEXT:    vmv.v.x v8, a0
; RV64-NEXT:    ret
  ret <vscale x 8 x float> zeroinitializer
}

define <vscale x 16 x float> @splat_zero_nxv16f32() {
; RV32-LABEL: splat_zero_nxv16f32:
; RV32:       # %bb.0:
; RV32-NEXT:    fmv.w.x fa5, zero
; RV32-NEXT:    vsetvli a0, zero, e32, m8, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv16f32:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.w.x fa5, zero
; RV64-NEXT:    fmv.x.w a0, fa5
; RV64-NEXT:    vsetvli a1, zero, e32, m8, ta, ma
; RV64-NEXT:    vmv.v.x v8, a0
; RV64-NEXT:    ret
  ret <vscale x 16 x float> zeroinitializer
}

define <vscale x 1 x double> @splat_zero_nxv1f64() {
; RV32-LABEL: splat_zero_nxv1f64:
; RV32:       # %bb.0:
; RV32-NEXT:    addi sp, sp, -16
; RV32-NEXT:    .cfi_def_cfa_offset 16
; RV32-NEXT:    sw zero, 8(sp)
; RV32-NEXT:    sw zero, 12(sp)
; RV32-NEXT:    fld fa5, 8(sp)
; RV32-NEXT:    vsetvli a0, zero, e64, m1, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    addi sp, sp, 16
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv1f64:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.d.x fa5, zero
; RV64-NEXT:    vsetvli a0, zero, e64, m1, ta, ma
; RV64-NEXT:    vfmv.v.f v8, fa5
; RV64-NEXT:    ret
  ret <vscale x 1 x double> zeroinitializer
}

define <vscale x 2 x double> @splat_zero_nxv2f64() {
; RV32-LABEL: splat_zero_nxv2f64:
; RV32:       # %bb.0:
; RV32-NEXT:    addi sp, sp, -16
; RV32-NEXT:    .cfi_def_cfa_offset 16
; RV32-NEXT:    sw zero, 8(sp)
; RV32-NEXT:    sw zero, 12(sp)
; RV32-NEXT:    fld fa5, 8(sp)
; RV32-NEXT:    vsetvli a0, zero, e64, m2, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    addi sp, sp, 16
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv2f64:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.d.x fa5, zero
; RV64-NEXT:    vsetvli a0, zero, e64, m2, ta, ma
; RV64-NEXT:    vfmv.v.f v8, fa5
; RV64-NEXT:    ret
  ret <vscale x 2 x double> zeroinitializer
}

define <vscale x 4 x double> @splat_zero_nxv4f64() {
; RV32-LABEL: splat_zero_nxv4f64:
; RV32:       # %bb.0:
; RV32-NEXT:    addi sp, sp, -16
; RV32-NEXT:    .cfi_def_cfa_offset 16
; RV32-NEXT:    sw zero, 8(sp)
; RV32-NEXT:    sw zero, 12(sp)
; RV32-NEXT:    fld fa5, 8(sp)
; RV32-NEXT:    vsetvli a0, zero, e64, m4, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    addi sp, sp, 16
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv4f64:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.d.x fa5, zero
; RV64-NEXT:    vsetvli a0, zero, e64, m4, ta, ma
; RV64-NEXT:    vfmv.v.f v8, fa5
; RV64-NEXT:    ret
  ret <vscale x 4 x double> zeroinitializer
}

define <vscale x 8 x double> @splat_zero_nxv8f64() {
; RV32-LABEL: splat_zero_nxv8f64:
; RV32:       # %bb.0:
; RV32-NEXT:    addi sp, sp, -16
; RV32-NEXT:    .cfi_def_cfa_offset 16
; RV32-NEXT:    sw zero, 8(sp)
; RV32-NEXT:    sw zero, 12(sp)
; RV32-NEXT:    fld fa5, 8(sp)
; RV32-NEXT:    vsetvli a0, zero, e64, m8, ta, ma
; RV32-NEXT:    vfmv.v.f v8, fa5
; RV32-NEXT:    addi sp, sp, 16
; RV32-NEXT:    ret
;
; RV64-LABEL: splat_zero_nxv8f64:
; RV64:       # %bb.0:
; RV64-NEXT:    fmv.d.x fa5, zero
; RV64-NEXT:    vsetvli a0, zero, e64, m8, ta, ma
; RV64-NEXT:    vfmv.v.f v8, fa5
; RV64-NEXT:    ret
  ret <vscale x 8 x double> zeroinitializer
}


