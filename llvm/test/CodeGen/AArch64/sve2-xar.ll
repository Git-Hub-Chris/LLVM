; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc -mtriple=aarch64 -mattr=+sve < %s -o - | FileCheck --check-prefix=SVE %s
; RUN: llc -mtriple=aarch64 -mattr=+sve2 < %s -o - | FileCheck --check-prefix=SVE2 %s

define <vscale x 2 x i64> @xar_nxv2i64_l(<vscale x 2 x i64> %x, <vscale x 2 x i64> %y) {
; SVE-LABEL: xar_nxv2i64_l:
; SVE:       // %bb.0:
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    lsr z1.d, z0.d, #4
; SVE-NEXT:    lsl z0.d, z0.d, #60
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv2i64_l:
; SVE2:       // %bb.0:
; SVE2-NEXT:    xar z0.d, z0.d, z1.d, #4
; SVE2-NEXT:    ret
    %a = xor <vscale x 2 x i64> %x, %y
    %b = call <vscale x 2 x i64> @llvm.fshl.nxv2i64(<vscale x 2 x i64> %a, <vscale x 2 x i64> %a, <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 60, i32 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer))
    ret <vscale x 2 x i64> %b
}

define <vscale x 2 x i64> @xar_nxv2i64_r(<vscale x 2 x i64> %x, <vscale x 2 x i64> %y) {
; SVE-LABEL: xar_nxv2i64_r:
; SVE:       // %bb.0:
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    lsl z1.d, z0.d, #60
; SVE-NEXT:    lsr z0.d, z0.d, #4
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv2i64_r:
; SVE2:       // %bb.0:
; SVE2-NEXT:    xar z0.d, z0.d, z1.d, #4
; SVE2-NEXT:    ret
    %a = xor <vscale x 2 x i64> %x, %y
    %b = call <vscale x 2 x i64> @llvm.fshr.nxv2i64(<vscale x 2 x i64> %a, <vscale x 2 x i64> %a, <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 4, i32 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer))
    ret <vscale x 2 x i64> %b
}


define <vscale x 4 x i32> @xar_nxv4i32_l(<vscale x 4 x i32> %x, <vscale x 4 x i32> %y) {
; SVE-LABEL: xar_nxv4i32_l:
; SVE:       // %bb.0:
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    lsr z1.s, z0.s, #4
; SVE-NEXT:    lsl z0.s, z0.s, #28
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv4i32_l:
; SVE2:       // %bb.0:
; SVE2-NEXT:    xar z0.s, z0.s, z1.s, #4
; SVE2-NEXT:    ret
    %a = xor <vscale x 4 x i32> %x, %y
    %b = call <vscale x 4 x i32> @llvm.fshl.nxv4i32(<vscale x 4 x i32> %a, <vscale x 4 x i32> %a, <vscale x 4 x i32> shufflevector (<vscale x 4 x i32> insertelement (<vscale x 4 x i32> poison, i32 28, i32 0), <vscale x 4 x i32> poison, <vscale x 4 x i32> zeroinitializer))
    ret <vscale x 4 x i32> %b
}

define <vscale x 4 x i32> @xar_nxv4i32_r(<vscale x 4 x i32> %x, <vscale x 4 x i32> %y) {
; SVE-LABEL: xar_nxv4i32_r:
; SVE:       // %bb.0:
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    lsl z1.s, z0.s, #28
; SVE-NEXT:    lsr z0.s, z0.s, #4
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv4i32_r:
; SVE2:       // %bb.0:
; SVE2-NEXT:    xar z0.s, z0.s, z1.s, #4
; SVE2-NEXT:    ret
    %a = xor <vscale x 4 x i32> %x, %y
    %b = call <vscale x 4 x i32> @llvm.fshr.nxv4i32(<vscale x 4 x i32> %a, <vscale x 4 x i32> %a, <vscale x 4 x i32> shufflevector (<vscale x 4 x i32> insertelement (<vscale x 4 x i32> poison, i32 4, i32 0), <vscale x 4 x i32> poison, <vscale x 4 x i32> zeroinitializer))
    ret <vscale x 4 x i32> %b
}

define <vscale x 8 x i16> @xar_nxv8i16_l(<vscale x 8 x i16> %x, <vscale x 8 x i16> %y) {
; SVE-LABEL: xar_nxv8i16_l:
; SVE:       // %bb.0:
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    lsr z1.h, z0.h, #4
; SVE-NEXT:    lsl z0.h, z0.h, #12
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv8i16_l:
; SVE2:       // %bb.0:
; SVE2-NEXT:    xar z0.h, z0.h, z1.h, #4
; SVE2-NEXT:    ret
    %a = xor <vscale x 8 x i16> %x, %y
    %b = call <vscale x 8 x i16> @llvm.fshl.nxv8i16(<vscale x 8 x i16> %a, <vscale x 8 x i16> %a, <vscale x 8 x i16> shufflevector (<vscale x 8 x i16> insertelement (<vscale x 8 x i16> poison, i16 12, i32 0), <vscale x 8 x i16> poison, <vscale x 8 x i32> zeroinitializer))
    ret <vscale x 8 x i16> %b
}

define <vscale x 8 x i16> @xar_nxv8i16_r(<vscale x 8 x i16> %x, <vscale x 8 x i16> %y) {
; SVE-LABEL: xar_nxv8i16_r:
; SVE:       // %bb.0:
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    lsl z1.h, z0.h, #12
; SVE-NEXT:    lsr z0.h, z0.h, #4
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv8i16_r:
; SVE2:       // %bb.0:
; SVE2-NEXT:    xar z0.h, z0.h, z1.h, #4
; SVE2-NEXT:    ret
    %a = xor <vscale x 8 x i16> %x, %y
    %b = call <vscale x 8 x i16> @llvm.fshr.nxv8i16(<vscale x 8 x i16> %a, <vscale x 8 x i16> %a, <vscale x 8 x i16> shufflevector (<vscale x 8 x i16> insertelement (<vscale x 8 x i16> poison, i16 4, i32 0), <vscale x 8 x i16> poison, <vscale x 8 x i32> zeroinitializer))
    ret <vscale x 8 x i16> %b
}

define <vscale x 16 x i8> @xar_nxv16i8_l(<vscale x 16 x i8> %x, <vscale x 16 x i8> %y) {
; SVE-LABEL: xar_nxv16i8_l:
; SVE:       // %bb.0:
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    lsr z1.b, z0.b, #4
; SVE-NEXT:    lsl z0.b, z0.b, #4
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv16i8_l:
; SVE2:       // %bb.0:
; SVE2-NEXT:    xar z0.b, z0.b, z1.b, #4
; SVE2-NEXT:    ret
    %a = xor <vscale x 16 x i8> %x, %y
    %b = call <vscale x 16 x i8> @llvm.fshl.nxv16i8(<vscale x 16 x i8> %a, <vscale x 16 x i8> %a, <vscale x 16 x i8> shufflevector (<vscale x 16 x i8> insertelement (<vscale x 16 x i8> poison, i8 4, i32 0), <vscale x 16 x i8> poison, <vscale x 16 x i32> zeroinitializer))
    ret <vscale x 16 x i8> %b
}

define <vscale x 16 x i8> @xar_nxv16i8_r(<vscale x 16 x i8> %x, <vscale x 16 x i8> %y) {
; SVE-LABEL: xar_nxv16i8_r:
; SVE:       // %bb.0:
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    lsl z1.b, z0.b, #4
; SVE-NEXT:    lsr z0.b, z0.b, #4
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv16i8_r:
; SVE2:       // %bb.0:
; SVE2-NEXT:    xar z0.b, z0.b, z1.b, #4
; SVE2-NEXT:    ret
    %a = xor <vscale x 16 x i8> %x, %y
    %b = call <vscale x 16 x i8> @llvm.fshr.nxv16i8(<vscale x 16 x i8> %a, <vscale x 16 x i8> %a, <vscale x 16 x i8> shufflevector (<vscale x 16 x i8> insertelement (<vscale x 16 x i8> poison, i8 4, i32 0), <vscale x 16 x i8> poison, <vscale x 16 x i32> zeroinitializer))
    ret <vscale x 16 x i8> %b
}


define <vscale x 2 x i64> @xar_nxv2i64_l_neg1(<vscale x 2 x i64> %x, <vscale x 2 x i64> %y, <vscale x 2 x i64> %z) {
; SVE-LABEL: xar_nxv2i64_l_neg1:
; SVE:       // %bb.0:
; SVE-NEXT:    mov z3.d, z2.d
; SVE-NEXT:    ptrue p0.d
; SVE-NEXT:    subr z2.d, z2.d, #0 // =0x0
; SVE-NEXT:    eor z0.d, z0.d, z1.d
; SVE-NEXT:    and z2.d, z2.d, #0x3f
; SVE-NEXT:    and z3.d, z3.d, #0x3f
; SVE-NEXT:    movprfx z1, z0
; SVE-NEXT:    lsl z1.d, p0/m, z1.d, z3.d
; SVE-NEXT:    lsr z0.d, p0/m, z0.d, z2.d
; SVE-NEXT:    orr z0.d, z1.d, z0.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv2i64_l_neg1:
; SVE2:       // %bb.0:
; SVE2-NEXT:    mov z3.d, z2.d
; SVE2-NEXT:    ptrue p0.d
; SVE2-NEXT:    subr z2.d, z2.d, #0 // =0x0
; SVE2-NEXT:    eor z0.d, z0.d, z1.d
; SVE2-NEXT:    and z2.d, z2.d, #0x3f
; SVE2-NEXT:    and z3.d, z3.d, #0x3f
; SVE2-NEXT:    movprfx z1, z0
; SVE2-NEXT:    lsl z1.d, p0/m, z1.d, z3.d
; SVE2-NEXT:    lsr z0.d, p0/m, z0.d, z2.d
; SVE2-NEXT:    orr z0.d, z1.d, z0.d
; SVE2-NEXT:    ret
    %a = xor <vscale x 2 x i64> %x, %y
    %b = call <vscale x 2 x i64> @llvm.fshl.nxv2i64(<vscale x 2 x i64> %a, <vscale x 2 x i64> %a, <vscale x 2 x i64> %z)
    ret <vscale x 2 x i64> %b
}

; TODO: We could use usra instruction here.
define <vscale x 2 x i64> @xar_nxv2i64_l_neg2(<vscale x 2 x i64> %x, <vscale x 2 x i64> %y) {
; SVE-LABEL: xar_nxv2i64_l_neg2:
; SVE:       // %bb.0:
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    lsr z1.d, z0.d, #4
; SVE-NEXT:    lsl z0.d, z0.d, #60
; SVE-NEXT:    orr z0.d, z0.d, z1.d
; SVE-NEXT:    ret
;
; SVE2-LABEL: xar_nxv2i64_l_neg2:
; SVE2:       // %bb.0:
; SVE2-NEXT:    orr z0.d, z0.d, z1.d
; SVE2-NEXT:    lsr z1.d, z0.d, #4
; SVE2-NEXT:    lsl z0.d, z0.d, #60
; SVE2-NEXT:    orr z0.d, z0.d, z1.d
; SVE2-NEXT:    ret
    %a = or <vscale x 2 x i64> %x, %y
    %b = call <vscale x 2 x i64> @llvm.fshl.nxv2i64(<vscale x 2 x i64> %a, <vscale x 2 x i64> %a, <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 60, i32 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer))
    ret <vscale x 2 x i64> %b
}

declare <vscale x 2 x i64> @llvm.fshl.nxv2i64(<vscale x 2 x i64>, <vscale x 2 x i64>, <vscale x 2 x i64>)
declare <vscale x 4 x i32> @llvm.fshl.nxv4i32(<vscale x 4 x i32>, <vscale x 4 x i32>, <vscale x 4 x i32>)
declare <vscale x 8 x i16> @llvm.fshl.nxv8i16(<vscale x 8 x i16>, <vscale x 8 x i16>, <vscale x 8 x i16>)
declare <vscale x 16 x i8> @llvm.fshl.nxv16i8(<vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>)
declare <vscale x 2 x i64> @llvm.fshr.nxv2i64(<vscale x 2 x i64>, <vscale x 2 x i64>, <vscale x 2 x i64>)
declare <vscale x 4 x i32> @llvm.fshr.nxv4i32(<vscale x 4 x i32>, <vscale x 4 x i32>, <vscale x 4 x i32>)
declare <vscale x 8 x i16> @llvm.fshr.nxv8i16(<vscale x 8 x i16>, <vscale x 8 x i16>, <vscale x 8 x i16>)
declare <vscale x 16 x i8> @llvm.fshr.nxv16i8(<vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>)
