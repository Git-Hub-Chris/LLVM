# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -debugify-and-strip-all-safe -run-pass=aarch64-prelegalizer-combiner -verify-machineinstrs -mtriple aarch64-unknown-unknown %s -o - | FileCheck %s
---
# add, _ = sadde(_, _, In)
name:            carryout_unused
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: carryout_unused
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %carry_in:_(s1) = G_TRUNC [[COPY1]](s64)
    ; CHECK-NEXT: [[ADD:%[0-9]+]]:_(s64) = G_ADD [[COPY]], [[COPY]]
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT %carry_in(s1)
    ; CHECK-NEXT: %add:_(s64) = G_ADD [[ADD]], [[ZEXT]]
    ; CHECK-NEXT: $x0 = COPY %add(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %lhs:_(s64) = COPY %3
    %rhs:_(s64) = COPY %3
    %carry_in:_(s1) = G_TRUNC %4
    %add:_(s64), %carry_out:_(s1) = G_SADDE %lhs, %rhs, %carry_in
    $x0 = COPY %add
...
---
# add, _ = uadde(_, _, In)
name:            carryout_unused_unsigned
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: carryout_unused_unsigned
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %carry_in:_(s1) = G_TRUNC [[COPY1]](s64)
    ; CHECK-NEXT: %add:_(s64), %carry_out:_(s1) = G_UADDE [[COPY]], [[COPY]], %carry_in
    ; CHECK-NEXT: $x0 = COPY %add(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %lhs:_(s64) = COPY %3
    %rhs:_(s64) = COPY %3
    %carry_in:_(s1) = G_TRUNC %4
    %add:_(s64), %carry_out:_(s1) = G_UADDE %lhs, %rhs, %carry_in
    $x0 = COPY %add
...
---
# add, multi_c = sadde(L, R, In)
name:            multi_use_unsigned
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: multi_use_unsigned
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %carry_in:_(s1) = G_TRUNC [[COPY1]](s64)
    ; CHECK-NEXT: %add:_(s64), %carry_out:_(s1) = G_UADDE [[COPY]], [[COPY]], %carry_in
    ; CHECK-NEXT: %carry_out_ext:_(s64) = G_ANYEXT %carry_out(s1)
    ; CHECK-NEXT: %carry_out_ext2:_(s64) = G_ANYEXT %carry_out(s1)
    ; CHECK-NEXT: $x0 = COPY %add(s64)
    ; CHECK-NEXT: $x1 = COPY %carry_out_ext(s64)
    ; CHECK-NEXT: $x2 = COPY %carry_out_ext2(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %lhs:_(s64) = COPY %3
    %rhs:_(s64) = COPY %3
    %carry_in:_(s1) = G_TRUNC %4
    %add:_(s64), %carry_out:_(s1) = G_UADDE %lhs, %rhs, %carry_in
    %carry_out_ext:_(s64) = G_ANYEXT %carry_out
    %carry_out_ext2:_(s64) = G_ANYEXT %carry_out
    $x0 = COPY %add
    $x1 = COPY %carry_out_ext
    $x2 = COPY %carry_out_ext2
...
---
# add, c = sadde(L, R, In)
name:            constant_fold_signed
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: constant_fold_signed
    ; CHECK: %add:_(s64) = G_CONSTANT i64 29
    ; CHECK-NEXT: %carry_out_ext:_(s64) = G_CONSTANT i64 0
    ; CHECK-NEXT: $x0 = COPY %add(s64)
    ; CHECK-NEXT: $x1 = COPY %carry_out_ext(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = G_CONSTANT i64 1
    %lhs:_(s64) = G_CONSTANT i64 11
    %rhs:_(s64) = G_CONSTANT i64 17
    %carry_in:_(s1) = G_CONSTANT i1 1
    %add:_(s64), %carry_out:_(s1) = G_SADDE %lhs, %rhs, %carry_in
    %carry_out_ext:_(s64) = G_ANYEXT %carry_out
    $x0 = COPY %add
    $x1 = COPY %carry_out_ext
...
---
# add, c = uadde(L, R, In)
name:            constant_fold_unsigned
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: constant_fold_unsigned
    ; CHECK: %add:_(s64) = G_CONSTANT i64 27
    ; CHECK-NEXT: %carry_out_ext:_(s64) = G_CONSTANT i64 0
    ; CHECK-NEXT: $x0 = COPY %add(s64)
    ; CHECK-NEXT: $x1 = COPY %carry_out_ext(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = G_CONSTANT i64 1
    %lhs:_(s64) = G_CONSTANT i64 19
    %rhs:_(s64) = G_CONSTANT i64 7
    %carry_in:_(s1) = G_CONSTANT i1 1
    %add:_(s64), %carry_out:_(s1) = G_UADDE %lhs, %rhs, %carry_in
    %carry_out_ext:_(s64) = G_ANYEXT %carry_out
    $x0 = COPY %add
    $x1 = COPY %carry_out_ext
...
---
# add, c = uadde(L, R, In)
name:            canonicalize_to_rhs_plus_lower
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: canonicalize_to_rhs_plus_lower
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %lhs:_(s64) = G_CONSTANT i64 19
    ; CHECK-NEXT: %carry_in:_(s1) = G_TRUNC [[COPY1]](s64)
    ; CHECK-NEXT: [[UADDO:%[0-9]+]]:_(s64), [[UADDO1:%[0-9]+]]:_(s1) = G_UADDO [[COPY]], %lhs
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT %carry_in(s1)
    ; CHECK-NEXT: [[UADDO2:%[0-9]+]]:_(s64), [[UADDO3:%[0-9]+]]:_(s1) = G_UADDO [[UADDO]], [[ZEXT]]
    ; CHECK-NEXT: %carry_out:_(s1) = G_OR [[UADDO1]], [[UADDO3]]
    ; CHECK-NEXT: %carry_out_ext:_(s64) = G_ANYEXT %carry_out(s1)
    ; CHECK-NEXT: $x0 = COPY [[UADDO2]](s64)
    ; CHECK-NEXT: $x1 = COPY %carry_out_ext(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %lhs:_(s64) = G_CONSTANT i64 19
    %rhs:_(s64) = COPY %3
    %carry_in:_(s1) = G_TRUNC %4
    %add:_(s64), %carry_out:_(s1) = G_UADDE %lhs, %rhs, %carry_in
    %carry_out_ext:_(s64) = G_ANYEXT %carry_out
    $x0 = COPY %add
    $x1 = COPY %carry_out_ext
...
---
# add, c = sadde(L, R, 0)
name:            fold_to_addo_l_r
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: fold_to_addo_l_r
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %add:_(s64), %carry_out:_(s1) = G_SADDO [[COPY]], [[COPY1]]
    ; CHECK-NEXT: %carry_out_ext:_(s64) = G_ANYEXT %carry_out(s1)
    ; CHECK-NEXT: $x0 = COPY %add(s64)
    ; CHECK-NEXT: $x1 = COPY %carry_out_ext(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %lhs:_(s64) = COPY %3
    %rhs:_(s64) = COPY %4
    %carry_in:_(s1) = G_CONSTANT i1 0
    %add:_(s64), %carry_out:_(s1) = G_SADDE %lhs, %rhs, %carry_in
    %carry_out_ext:_(s64) = G_ANYEXT %carry_out
    $x0 = COPY %add
    $x1 = COPY %carry_out_ext
...
---
# add, c = sadde(L, 0, CarryIn)
name:            fold_to_addo_l_carryin
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: fold_to_addo_l_carryin
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %carry_in:_(s1) = G_TRUNC [[COPY1]](s64)
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT %carry_in(s1)
    ; CHECK-NEXT: %add:_(s64), %carry_out:_(s1) = G_SADDO [[COPY]], [[ZEXT]]
    ; CHECK-NEXT: %carry_out_ext:_(s64) = G_ANYEXT %carry_out(s1)
    ; CHECK-NEXT: $x0 = COPY %add(s64)
    ; CHECK-NEXT: $x1 = COPY %carry_out_ext(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %lhs:_(s64) = COPY %3
    %rhs:_(s64) = G_CONSTANT i64 0
    %carry_in:_(s1) = G_TRUNC %4
    %add:_(s64), %carry_out:_(s1) = G_SADDE %lhs, %rhs, %carry_in
    %carry_out_ext:_(s64) = G_ANYEXT %carry_out
    $x0 = COPY %add
    $x1 = COPY %carry_out_ext
...
---
# add, c = sadde(L, R, CarryIn)
name:            fold_to_lower_signed
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: fold_to_lower_signed
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %carry_in:_(s1) = G_TRUNC [[COPY1]](s64)
    ; CHECK-NEXT: [[SADDO:%[0-9]+]]:_(s64), [[SADDO1:%[0-9]+]]:_(s1) = G_SADDO [[COPY]], [[COPY1]]
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT %carry_in(s1)
    ; CHECK-NEXT: [[SADDO2:%[0-9]+]]:_(s64), [[SADDO3:%[0-9]+]]:_(s1) = G_SADDO [[SADDO]], [[ZEXT]]
    ; CHECK-NEXT: %carry_out:_(s1) = G_OR [[SADDO1]], [[SADDO3]]
    ; CHECK-NEXT: %carry_out_ext:_(s64) = G_ANYEXT %carry_out(s1)
    ; CHECK-NEXT: $x0 = COPY [[SADDO2]](s64)
    ; CHECK-NEXT: $x1 = COPY %carry_out_ext(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %lhs:_(s64) = COPY %3
    %rhs:_(s64) = COPY %4
    %carry_in:_(s1) = G_TRUNC %4
    %add:_(s64), %carry_out:_(s1) = G_SADDE %lhs, %rhs, %carry_in
    %carry_out_ext:_(s64) = G_ANYEXT %carry_out
    $x0 = COPY %add
    $x1 = COPY %carry_out_ext
...
---
# add, c = uadde(L, R, CarryIn)
name:            fold_to_lower_unsigned
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: fold_to_lower_unsigned
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %carry_in:_(s1) = G_TRUNC [[COPY1]](s64)
    ; CHECK-NEXT: [[UADDO:%[0-9]+]]:_(s64), [[UADDO1:%[0-9]+]]:_(s1) = G_UADDO [[COPY]], [[COPY1]]
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT %carry_in(s1)
    ; CHECK-NEXT: [[UADDO2:%[0-9]+]]:_(s64), [[UADDO3:%[0-9]+]]:_(s1) = G_UADDO [[UADDO]], [[ZEXT]]
    ; CHECK-NEXT: %carry_out:_(s1) = G_OR [[UADDO1]], [[UADDO3]]
    ; CHECK-NEXT: %carry_out_ext:_(s64) = G_ANYEXT %carry_out(s1)
    ; CHECK-NEXT: $x0 = COPY [[UADDO2]](s64)
    ; CHECK-NEXT: $x1 = COPY %carry_out_ext(s64)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %lhs:_(s64) = COPY %3
    %rhs:_(s64) = COPY %4
    %carry_in:_(s1) = G_TRUNC %4
    %add:_(s64), %carry_out:_(s1) = G_UADDE %lhs, %rhs, %carry_in
    %carry_out_ext:_(s64) = G_ANYEXT %carry_out
    $x0 = COPY %add
    $x1 = COPY %carry_out_ext
...
---
# add, c = uadde(L, R, CarryIn)
name:            fold_to_lower_vectorized
body:             |
  bb.0.entry:
    ; CHECK-LABEL: name: fold_to_lower_vectorized
    ; CHECK: [[COPY:%[0-9]+]]:_(s64) = COPY $x0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(s64) = COPY $x2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(s64) = COPY $x3
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:_(s64) = COPY $x4
    ; CHECK-NEXT: %onebit:_(s1) = G_TRUNC [[COPY4]](s64)
    ; CHECK-NEXT: %lhs:_(<2 x s64>) = G_BUILD_VECTOR [[COPY]](s64), [[COPY1]](s64)
    ; CHECK-NEXT: %rhs:_(<2 x s64>) = G_BUILD_VECTOR [[COPY2]](s64), [[COPY3]](s64)
    ; CHECK-NEXT: %carry_in:_(<2 x s1>) = G_BUILD_VECTOR %onebit(s1), %onebit(s1)
    ; CHECK-NEXT: [[UADDO:%[0-9]+]]:_(<2 x s64>), [[UADDO1:%[0-9]+]]:_(<2 x s1>) = G_UADDO %lhs, %rhs
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(<2 x s64>) = G_ZEXT %carry_in(<2 x s1>)
    ; CHECK-NEXT: [[UADDO2:%[0-9]+]]:_(<2 x s64>), [[UADDO3:%[0-9]+]]:_(<2 x s1>) = G_UADDO [[UADDO]], [[ZEXT]]
    ; CHECK-NEXT: %carry_out:_(<2 x s1>) = G_OR [[UADDO1]], [[UADDO3]]
    ; CHECK-NEXT: %zext:_(<2 x s64>) = G_ZEXT %carry_out(<2 x s1>)
    ; CHECK-NEXT: $q0 = COPY %zext(<2 x s64>)
    ; CHECK-NEXT: $q0 = COPY [[UADDO2]](<2 x s64>)
    %0:_(s64) = COPY $x0
    %1:_(s64) = COPY $x1
    %2:_(s64) = COPY $x2
    %3:_(s64) = COPY $x3
    %4:_(s64) = COPY $x4
    %onebit:_(s1) = G_TRUNC %4
    %lhs:_(<2 x s64>) = G_BUILD_VECTOR %0(s64), %1(s64)
    %rhs:_(<2 x s64>) = G_BUILD_VECTOR %2(s64), %3(s64)
    %carry_in:_(<2 x s1>) = G_BUILD_VECTOR %onebit(s1), %onebit(s1)
    %add:_(<2 x s64>), %carry_out:_(<2 x s1>) = G_UADDE %lhs, %rhs, %carry_in
    %zext:_(<2 x s64>) = G_ZEXT %carry_out(<2 x s1>)
    $q0 = COPY %zext
    $q0 = COPY %add
...
