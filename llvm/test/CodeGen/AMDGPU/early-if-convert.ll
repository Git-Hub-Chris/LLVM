; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN:  llc -amdgpu-scalarize-global-loads=false  -march=amdgcn -mcpu=verde -amdgpu-early-ifcvt=1 -amdgpu-codegenprepare-break-large-phis=0 -verify-machineinstrs < %s | FileCheck -check-prefix=GCN %s
; XUN: llc -march=amdgcn -mcpu=tonga -amdgpu-early-ifcvt=1 -verify-machineinstrs < %s | FileCheck -check-prefix=GCN %s

; Note: breaking up large PHIs is disabled to prevent some testcases from becoming
;  branchless.

; FIXME: This leaves behind a now unnecessary and with exec

define amdgpu_kernel void @test_vccnz_ifcvt_triangle(ptr addrspace(1) %out, ptr addrspace(1) %in) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s2
; GCN-NEXT:    s_mov_b32 s5, s3
; GCN-NEXT:    buffer_load_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_mov_b32 s2, s6
; GCN-NEXT:    s_mov_b32 s3, s7
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_cmp_neq_f32_e32 vcc, 1.0, v0
; GCN-NEXT:    v_add_f32_e32 v1, v0, v0
; GCN-NEXT:    s_and_b64 vcc, exec, vcc
; GCN-NEXT:    v_cndmask_b32_e32 v0, v1, v0, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load float, ptr addrspace(1) %in
  %cc = fcmp oeq float %v, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u = fadd float %v, %v
  br label %endif

endif:
  %r = phi float [ %v, %entry ], [ %u, %if ]
  store float %r, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @test_vccnz_ifcvt_diamond(ptr addrspace(1) %out, ptr addrspace(1) %in) #0 {
; GCN-LABEL: test_vccnz_ifcvt_diamond:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s2
; GCN-NEXT:    s_mov_b32 s5, s3
; GCN-NEXT:    buffer_load_dword v1, off, s[4:7], 0
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_cmp_neq_f32_e32 vcc, 1.0, v1
; GCN-NEXT:    s_cbranch_vccz .LBB1_4
; GCN-NEXT:  ; %bb.1: ; %else
; GCN-NEXT:    v_mul_f32_e32 v0, v1, v1
; GCN-NEXT:    s_mov_b64 s[2:3], 0
; GCN-NEXT:    s_cbranch_execnz .LBB1_3
; GCN-NEXT:  .LBB1_2: ; %if
; GCN-NEXT:    v_add_f32_e32 v0, v1, v1
; GCN-NEXT:  .LBB1_3: ; %endif
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
; GCN-NEXT:  .LBB1_4:
; GCN-NEXT:    s_mov_b64 s[2:3], -1
; GCN-NEXT:    ; implicit-def: $vgpr0
; GCN-NEXT:    s_branch .LBB1_2
entry:
  %v = load float, ptr addrspace(1) %in
  %cc = fcmp oeq float %v, 1.000000e+00
  br i1 %cc, label %if, label %else

if:
  %u0 = fadd float %v, %v
  br label %endif

else:
  %u1 = fmul float %v, %v
  br label %endif

endif:
  %r = phi float [ %u0, %if ], [ %u1, %else ]
  store float %r, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @test_vccnz_ifcvt_triangle_vcc_clobber(ptr addrspace(1) %out, ptr addrspace(1) %in, float %k) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle_vcc_clobber:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s8, s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; clobber vcc
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s6
; GCN-NEXT:    s_mov_b32 s1, s7
; GCN-NEXT:    buffer_load_dword v0, off, s[0:3], 0
; GCN-NEXT:    v_cmp_neq_f32_e64 s[0:1], s8, 1.0
; GCN-NEXT:    s_and_b64 s[0:1], exec, s[0:1]
; GCN-NEXT:    s_mov_b32 s6, s2
; GCN-NEXT:    s_mov_b32 s7, s3
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v0, v0
; GCN-NEXT:    s_mov_b64 vcc, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v1, v0, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load i32, ptr addrspace(1) %in
  %cc = fcmp oeq float %k, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  call void asm "; clobber $0", "~{vcc}"() #0
  %u = add i32 %v, %v
  br label %endif

endif:
  %r = phi i32 [ %v, %entry ], [ %u, %if ]
  store i32 %r, ptr addrspace(1) %out
  ret void
}

; Longest chain of cheap instructions to convert
define amdgpu_kernel void @test_vccnz_ifcvt_triangle_max_cheap(ptr addrspace(1) %out, ptr addrspace(1) %in) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle_max_cheap:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s2
; GCN-NEXT:    s_mov_b32 s5, s3
; GCN-NEXT:    buffer_load_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_mov_b32 s2, s6
; GCN-NEXT:    s_mov_b32 s3, s7
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v0
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_cmp_neq_f32_e32 vcc, 1.0, v0
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    s_and_b64 vcc, exec, vcc
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_cndmask_b32_e32 v0, v1, v0, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load float, ptr addrspace(1) %in
  %cc = fcmp oeq float %v, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u.0 = fmul float %v, %v
  %u.1 = fmul float %v, %u.0
  %u.2 = fmul float %v, %u.1
  %u.3 = fmul float %v, %u.2
  %u.4 = fmul float %v, %u.3
  %u.5 = fmul float %v, %u.4
  %u.6 = fmul float %v, %u.5
  %u.7 = fmul float %v, %u.6
  %u.8 = fmul float %v, %u.7
  br label %endif

endif:
  %r = phi float [ %v, %entry ], [ %u.8, %if ]
  store float %r, ptr addrspace(1) %out
  ret void
}

; Short chain of cheap instructions to not convert
define amdgpu_kernel void @test_vccnz_ifcvt_triangle_min_expensive(ptr addrspace(1) %out, ptr addrspace(1) %in) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle_min_expensive:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s2
; GCN-NEXT:    s_mov_b32 s5, s3
; GCN-NEXT:    buffer_load_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_cmp_neq_f32_e32 vcc, 1.0, v0
; GCN-NEXT:    s_cbranch_vccnz .LBB4_2
; GCN-NEXT:  ; %bb.1: ; %if
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v0
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v1
; GCN-NEXT:    v_mul_f32_e32 v0, v0, v1
; GCN-NEXT:  .LBB4_2: ; %endif
; GCN-NEXT:    s_mov_b32 s2, s6
; GCN-NEXT:    s_mov_b32 s3, s7
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load float, ptr addrspace(1) %in
  %cc = fcmp oeq float %v, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u.0 = fmul float %v, %v
  %u.1 = fmul float %v, %u.0
  %u.2 = fmul float %v, %u.1
  %u.3 = fmul float %v, %u.2
  %u.4 = fmul float %v, %u.3
  %u.5 = fmul float %v, %u.4
  %u.6 = fmul float %v, %u.5
  %u.7 = fmul float %v, %u.6
  %u.8 = fmul float %v, %u.7
  %u.9 = fmul float %v, %u.8
  br label %endif

endif:
  %r = phi float [ %v, %entry ], [ %u.9, %if ]
  store float %r, ptr addrspace(1) %out
  ret void
}

; Should still branch over fdiv expansion
define amdgpu_kernel void @test_vccnz_ifcvt_triangle_expensive(ptr addrspace(1) %out, ptr addrspace(1) %in) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle_expensive:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s2
; GCN-NEXT:    s_mov_b32 s5, s3
; GCN-NEXT:    buffer_load_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_cmp_neq_f32_e32 vcc, 1.0, v0
; GCN-NEXT:    s_cbranch_vccnz .LBB5_2
; GCN-NEXT:  ; %bb.1: ; %if
; GCN-NEXT:    v_div_scale_f32 v1, vcc, v0, v0, v0
; GCN-NEXT:    v_rcp_f32_e32 v2, v1
; GCN-NEXT:    v_fma_f32 v3, -v1, v2, 1.0
; GCN-NEXT:    v_fma_f32 v2, v3, v2, v2
; GCN-NEXT:    v_mul_f32_e32 v3, v1, v2
; GCN-NEXT:    v_fma_f32 v4, -v1, v3, v1
; GCN-NEXT:    v_fma_f32 v3, v4, v2, v3
; GCN-NEXT:    v_fma_f32 v1, -v1, v3, v1
; GCN-NEXT:    v_div_fmas_f32 v1, v1, v2, v3
; GCN-NEXT:    v_div_fixup_f32 v0, v1, v0, v0
; GCN-NEXT:  .LBB5_2: ; %endif
; GCN-NEXT:    s_mov_b32 s2, s6
; GCN-NEXT:    s_mov_b32 s3, s7
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load float, ptr addrspace(1) %in
  %cc = fcmp oeq float %v, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u = fdiv float %v, %v
  br label %endif

endif:
  %r = phi float [ %v, %entry ], [ %u, %if ]
  store float %r, ptr addrspace(1) %out
  ret void
}

; vcc branch with SGPR inputs
define amdgpu_kernel void @test_vccnz_sgpr_ifcvt_triangle(ptr addrspace(1) %out, ptr addrspace(4) %in, float %cnd) #0 {
; GCN-LABEL: test_vccnz_sgpr_ifcvt_triangle:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s1, s[0:1], 0xd
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dword s0, s[6:7], 0x0
; GCN-NEXT:    v_cmp_neq_f32_e64 s[2:3], s1, 1.0
; GCN-NEXT:    s_and_b64 vcc, exec, s[2:3]
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b64 vcc, vcc
; GCN-NEXT:    s_cbranch_vccnz .LBB6_2
; GCN-NEXT:  ; %bb.1: ; %if
; GCN-NEXT:    s_add_i32 s0, s0, s0
; GCN-NEXT:  .LBB6_2: ; %endif
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load i32, ptr addrspace(4) %in
  %cc = fcmp oeq float %cnd, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u = add i32 %v, %v
  br label %endif

endif:
  %r = phi i32 [ %v, %entry ], [ %u, %if ]
  store i32 %r, ptr addrspace(1) %out
  ret void

}

define amdgpu_kernel void @test_vccnz_ifcvt_triangle_constant_load(ptr addrspace(1) %out, ptr addrspace(4) %in) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle_constant_load:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dword s2, s[2:3], 0x0
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_cmp_neq_f32_e64 s[4:5], s2, 1.0
; GCN-NEXT:    v_mov_b32_e32 v0, s2
; GCN-NEXT:    v_add_f32_e64 v1, s2, s2
; GCN-NEXT:    s_and_b64 vcc, exec, s[4:5]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v1, v0, vcc
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load float, ptr addrspace(4) %in
  %cc = fcmp oeq float %v, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u = fadd float %v, %v
  br label %endif

endif:
  %r = phi float [ %v, %entry ], [ %u, %if ]
  store float %r, ptr addrspace(1) %out
  ret void
}

; Due to broken cost heuristic, this is not if converted like
; test_vccnz_ifcvt_triangle_constant_load even though it should be.
define amdgpu_kernel void @test_vccnz_ifcvt_triangle_argload(ptr addrspace(1) %out, float %v) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle_argload:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dword s2, s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_cmp_neq_f32_e64 s[4:5], s2, 1.0
; GCN-NEXT:    v_mov_b32_e32 v0, s2
; GCN-NEXT:    v_add_f32_e64 v1, s2, s2
; GCN-NEXT:    s_and_b64 vcc, exec, s[4:5]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v1, v0, vcc
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
entry:
  %cc = fcmp oeq float %v, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u = fadd float %v, %v
  br label %endif

endif:
  %r = phi float [ %v, %entry ], [ %u, %if ]
  store float %r, ptr addrspace(1) %out
  ret void
}

; Scalar branch and scalar inputs
define amdgpu_kernel void @test_scc1_sgpr_ifcvt_triangle(ptr addrspace(4) %in, i32 %cond) #0 {
; GCN-LABEL: test_scc1_sgpr_ifcvt_triangle:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dword s1, s[2:3], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_add_i32 s2, s1, s1
; GCN-NEXT:    s_cmp_lg_u32 s0, 1
; GCN-NEXT:    s_cselect_b32 s0, s1, s2
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; reg use s0
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_endpgm
entry:
  %v = load i32, ptr addrspace(4) %in
  %cc = icmp eq i32 %cond, 1
  br i1 %cc, label %if, label %endif

if:
  %u = add i32 %v, %v
  br label %endif

endif:
  %r = phi i32 [ %v, %entry ], [ %u, %if ]
  call void asm sideeffect "; reg use $0", "s"(i32 %r) #0
  ret void
}

; FIXME: Should be able to use VALU compare and select
; Scalar branch but VGPR select operands
define amdgpu_kernel void @test_scc1_vgpr_ifcvt_triangle(ptr addrspace(1) %out, ptr addrspace(1) %in, i32 %cond) #0 {
; GCN-LABEL: test_scc1_vgpr_ifcvt_triangle:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s8, s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s6
; GCN-NEXT:    s_mov_b32 s1, s7
; GCN-NEXT:    buffer_load_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_cmp_lg_u32 s8, 1
; GCN-NEXT:    s_cbranch_scc1 .LBB10_2
; GCN-NEXT:  ; %bb.1: ; %if
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_add_f32_e32 v0, v0, v0
; GCN-NEXT:  .LBB10_2: ; %endif
; GCN-NEXT:    s_mov_b32 s6, s2
; GCN-NEXT:    s_mov_b32 s7, s3
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load float, ptr addrspace(1) %in
  %cc = icmp eq i32 %cond, 1
  br i1 %cc, label %if, label %endif

if:
  %u = fadd float %v, %v
  br label %endif

endif:
  %r = phi float [ %v, %entry ], [ %u, %if ]
  store float %r, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @test_scc1_sgpr_ifcvt_triangle64(ptr addrspace(4) %in, i32 %cond) #0 {
; GCN-LABEL: test_scc1_sgpr_ifcvt_triangle64:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s4, s[0:1], 0xb
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[2:3], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_add_u32 s2, s0, s0
; GCN-NEXT:    s_addc_u32 s3, s1, s1
; GCN-NEXT:    s_cmp_lg_u32 s4, 1
; GCN-NEXT:    s_cselect_b64 s[0:1], s[0:1], s[2:3]
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; reg use s[0:1]
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_endpgm
entry:
  %v = load i64, ptr addrspace(4) %in
  %cc = icmp eq i32 %cond, 1
  br i1 %cc, label %if, label %endif

if:
  %u = add i64 %v, %v
  br label %endif

endif:
  %r = phi i64 [ %v, %entry ], [ %u, %if ]
  call void asm sideeffect "; reg use $0", "s"(i64 %r) #0
  ret void
}

; TODO: Can do s_cselect_b64; s_cselect_b32
define amdgpu_kernel void @test_scc1_sgpr_ifcvt_triangle96(ptr addrspace(4) %in, i32 %cond) #0 {
; GCN-LABEL: test_scc1_sgpr_ifcvt_triangle96:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s7, s[0:1], 0xb
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[2:3], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_add_i32 s6, s2, s2
; GCN-NEXT:    s_add_i32 s5, s1, s1
; GCN-NEXT:    s_add_i32 s4, s0, s0
; GCN-NEXT:    s_cmp_lg_u32 s7, 1
; GCN-NEXT:    s_cselect_b32 s0, s0, s4
; GCN-NEXT:    s_cselect_b32 s1, s1, s5
; GCN-NEXT:    s_cselect_b32 s2, s2, s6
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; reg use s[0:3]
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_endpgm
entry:
  %v = load <3 x i32>, ptr addrspace(4) %in
  %cc = icmp eq i32 %cond, 1
  br i1 %cc, label %if, label %endif

if:
  %u = add <3 x i32> %v, %v
  br label %endif

endif:
  %r = phi <3 x i32> [ %v, %entry ], [ %u, %if ]
  %r.ext = shufflevector <3 x i32> %r, <3 x i32> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void asm sideeffect "; reg use $0", "s"(<4 x i32> %r.ext) #0
  ret void
}

define amdgpu_kernel void @test_scc1_sgpr_ifcvt_triangle128(ptr addrspace(4) %in, i32 %cond) #0 {
; GCN-LABEL: test_scc1_sgpr_ifcvt_triangle128:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s8, s[0:1], 0xb
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[2:3], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_add_i32 s7, s3, s3
; GCN-NEXT:    s_add_i32 s6, s2, s2
; GCN-NEXT:    s_add_i32 s5, s1, s1
; GCN-NEXT:    s_add_i32 s4, s0, s0
; GCN-NEXT:    s_cmp_lg_u32 s8, 1
; GCN-NEXT:    s_cselect_b64 s[0:1], s[0:1], s[4:5]
; GCN-NEXT:    s_cselect_b64 s[2:3], s[2:3], s[6:7]
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; reg use s[0:3]
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_endpgm
entry:
  %v = load <4 x i32>, ptr addrspace(4) %in
  %cc = icmp eq i32 %cond, 1
  br i1 %cc, label %if, label %endif

if:
  %u = add <4 x i32> %v, %v
  br label %endif

endif:
  %r = phi <4 x i32> [ %v, %entry ], [ %u, %if ]
  call void asm sideeffect "; reg use $0", "s"(<4 x i32> %r) #0
  ret void
}

define amdgpu_kernel void @uniform_if_swap_br_targets_scc_constant_select(i32 %cond, ptr addrspace(1) %out) {
; GCN-LABEL: uniform_if_swap_br_targets_scc_constant_select:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dword s2, s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_cmp_lg_u32 s2, 0
; GCN-NEXT:    s_cselect_b32 s4, 0, 1
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    v_mov_b32_e32 v0, s4
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
entry:
  %cmp0 = icmp eq i32 %cond, 0
  br i1 %cmp0, label %else, label %if

if:
  br label %done

else:
  br label %done

done:
  %value = phi i32 [0, %if], [1, %else]
  store i32 %value, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ifcvt_undef_scc(i32 %cond, ptr addrspace(1) %out) {
; GCN-LABEL: ifcvt_undef_scc:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    s_cselect_b32 s4, 0, 1
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    v_mov_b32_e32 v0, s4
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
entry:
  br i1 undef, label %else, label %if

if:
  br label %done

else:
  br label %done

done:
  %value = phi i32 [0, %if], [1, %else]
  store i32 %value, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @test_vccnz_ifcvt_triangle256(ptr addrspace(1) %out, ptr addrspace(1) %in, float %cnd) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle256:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s8, s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s6
; GCN-NEXT:    s_mov_b32 s1, s7
; GCN-NEXT:    buffer_load_dwordx4 v[0:3], off, s[0:3], 0
; GCN-NEXT:    buffer_load_dwordx4 v[4:7], off, s[0:3], 0 offset:16
; GCN-NEXT:    v_cmp_neq_f32_e64 s[0:1], s8, 1.0
; GCN-NEXT:    s_and_b64 vcc, exec, s[0:1]
; GCN-NEXT:    s_cbranch_vccnz .LBB16_2
; GCN-NEXT:  ; %bb.1: ; %if
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v7, v7
; GCN-NEXT:    v_add_i32_e32 v6, vcc, v6, v6
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v5, v5
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v4, v4
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v3, v3
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v2
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v1
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v0
; GCN-NEXT:  .LBB16_2: ; %endif
; GCN-NEXT:    s_mov_b32 s6, s2
; GCN-NEXT:    s_mov_b32 s7, s3
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    buffer_store_dwordx4 v[4:7], off, s[4:7], 0 offset:16
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load <8 x i32>, ptr addrspace(1) %in
  %cc = fcmp oeq float %cnd, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u = add <8 x i32> %v, %v
  br label %endif

endif:
  %r = phi <8 x i32> [ %v, %entry ], [ %u, %if ]
  store <8 x i32> %r, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @test_vccnz_ifcvt_triangle512(ptr addrspace(1) %out, ptr addrspace(1) %in, float %cnd) #0 {
; GCN-LABEL: test_vccnz_ifcvt_triangle512:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s8, s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s6
; GCN-NEXT:    s_mov_b32 s1, s7
; GCN-NEXT:    buffer_load_dwordx4 v[0:3], off, s[0:3], 0
; GCN-NEXT:    buffer_load_dwordx4 v[4:7], off, s[0:3], 0 offset:16
; GCN-NEXT:    buffer_load_dwordx4 v[8:11], off, s[0:3], 0 offset:32
; GCN-NEXT:    buffer_load_dwordx4 v[12:15], off, s[0:3], 0 offset:48
; GCN-NEXT:    v_cmp_neq_f32_e64 s[6:7], s8, 1.0
; GCN-NEXT:    s_and_b64 vcc, exec, s[6:7]
; GCN-NEXT:    s_cbranch_vccnz .LBB17_2
; GCN-NEXT:  ; %bb.1: ; %if
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_add_i32_e32 v15, vcc, v15, v15
; GCN-NEXT:    v_add_i32_e32 v14, vcc, v14, v14
; GCN-NEXT:    v_add_i32_e32 v13, vcc, v13, v13
; GCN-NEXT:    v_add_i32_e32 v12, vcc, v12, v12
; GCN-NEXT:    v_add_i32_e32 v11, vcc, v11, v11
; GCN-NEXT:    v_add_i32_e32 v10, vcc, v10, v10
; GCN-NEXT:    v_add_i32_e32 v9, vcc, v9, v9
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v8, v8
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v7, v7
; GCN-NEXT:    v_add_i32_e32 v6, vcc, v6, v6
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v5, v5
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v4, v4
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v3, v3
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v2
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v1
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v0
; GCN-NEXT:  .LBB17_2: ; %endif
; GCN-NEXT:    s_mov_b32 s6, s2
; GCN-NEXT:    s_mov_b32 s7, s3
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    buffer_store_dwordx4 v[12:15], off, s[4:7], 0 offset:48
; GCN-NEXT:    buffer_store_dwordx4 v[8:11], off, s[4:7], 0 offset:32
; GCN-NEXT:    buffer_store_dwordx4 v[4:7], off, s[4:7], 0 offset:16
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
entry:
  %v = load <16 x i32>, ptr addrspace(1) %in
  %cc = fcmp oeq float %cnd, 1.000000e+00
  br i1 %cc, label %if, label %endif

if:
  %u = add <16 x i32> %v, %v
  br label %endif

endif:
  %r = phi <16 x i32> [ %v, %entry ], [ %u, %if ]
  store <16 x i32> %r, ptr addrspace(1) %out
  ret void
}

attributes #0 = { nounwind }
