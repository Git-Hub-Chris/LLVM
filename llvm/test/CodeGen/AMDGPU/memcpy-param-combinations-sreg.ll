; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5

; RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx1030 %s -o - | FileCheck %s

; Testing codegen for memcpy and memmove with scalar operands for all combinations of the following parameters:
;     address space combinations (dst, src): (0, 0), (1, 1), (3, 3), (1, 4), (5, 5)
;     alignment: 1, 2, 4, 8, 16
;     sizes: 32


define void @memcpy_p0_p0_sz32_align_1_1(ptr addrspace(0) align 1 inreg %dst, ptr addrspace(0) align 1 readonly inreg %src) {
; CHECK-LABEL: memcpy_p0_p0_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s6
; CHECK-NEXT:    v_mov_b32_e32 v1, s7
; CHECK-NEXT:    v_mov_b32_e32 v2, s4
; CHECK-NEXT:    v_mov_b32_e32 v3, s5
; CHECK-NEXT:    s_clause 0xf
; CHECK-NEXT:    flat_load_ubyte v4, v[0:1] offset:15
; CHECK-NEXT:    flat_load_ubyte v5, v[0:1] offset:14
; CHECK-NEXT:    flat_load_ubyte v6, v[0:1] offset:13
; CHECK-NEXT:    flat_load_ubyte v7, v[0:1] offset:12
; CHECK-NEXT:    flat_load_ubyte v8, v[0:1] offset:11
; CHECK-NEXT:    flat_load_ubyte v9, v[0:1] offset:10
; CHECK-NEXT:    flat_load_ubyte v10, v[0:1] offset:9
; CHECK-NEXT:    flat_load_ubyte v11, v[0:1] offset:8
; CHECK-NEXT:    flat_load_ubyte v12, v[0:1] offset:7
; CHECK-NEXT:    flat_load_ubyte v13, v[0:1] offset:6
; CHECK-NEXT:    flat_load_ubyte v14, v[0:1] offset:5
; CHECK-NEXT:    flat_load_ubyte v15, v[0:1] offset:4
; CHECK-NEXT:    flat_load_ubyte v16, v[0:1] offset:3
; CHECK-NEXT:    flat_load_ubyte v17, v[0:1] offset:2
; CHECK-NEXT:    flat_load_ubyte v18, v[0:1] offset:1
; CHECK-NEXT:    flat_load_ubyte v19, v[0:1]
; CHECK-NEXT:    s_waitcnt vmcnt(15) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v4 offset:15
; CHECK-NEXT:    s_waitcnt vmcnt(14) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v5 offset:14
; CHECK-NEXT:    s_waitcnt vmcnt(13) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v6 offset:13
; CHECK-NEXT:    s_waitcnt vmcnt(12) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v7 offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(11) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v8 offset:11
; CHECK-NEXT:    s_waitcnt vmcnt(10) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v9 offset:10
; CHECK-NEXT:    s_waitcnt vmcnt(9) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v10 offset:9
; CHECK-NEXT:    s_waitcnt vmcnt(8) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v11 offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(7) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v12 offset:7
; CHECK-NEXT:    s_waitcnt vmcnt(6) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v13 offset:6
; CHECK-NEXT:    s_waitcnt vmcnt(5) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v14 offset:5
; CHECK-NEXT:    s_waitcnt vmcnt(4) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v15 offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(3) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v16 offset:3
; CHECK-NEXT:    s_waitcnt vmcnt(2) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v17 offset:2
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v18 offset:1
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v19
; CHECK-NEXT:    s_clause 0xf
; CHECK-NEXT:    flat_load_ubyte v4, v[0:1] offset:31
; CHECK-NEXT:    flat_load_ubyte v5, v[0:1] offset:30
; CHECK-NEXT:    flat_load_ubyte v6, v[0:1] offset:29
; CHECK-NEXT:    flat_load_ubyte v7, v[0:1] offset:28
; CHECK-NEXT:    flat_load_ubyte v8, v[0:1] offset:27
; CHECK-NEXT:    flat_load_ubyte v9, v[0:1] offset:26
; CHECK-NEXT:    flat_load_ubyte v10, v[0:1] offset:25
; CHECK-NEXT:    flat_load_ubyte v11, v[0:1] offset:24
; CHECK-NEXT:    flat_load_ubyte v12, v[0:1] offset:23
; CHECK-NEXT:    flat_load_ubyte v13, v[0:1] offset:22
; CHECK-NEXT:    flat_load_ubyte v14, v[0:1] offset:21
; CHECK-NEXT:    flat_load_ubyte v15, v[0:1] offset:20
; CHECK-NEXT:    flat_load_ubyte v16, v[0:1] offset:19
; CHECK-NEXT:    flat_load_ubyte v17, v[0:1] offset:18
; CHECK-NEXT:    flat_load_ubyte v18, v[0:1] offset:17
; CHECK-NEXT:    flat_load_ubyte v0, v[0:1] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(15) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v4 offset:31
; CHECK-NEXT:    s_waitcnt vmcnt(14) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v5 offset:30
; CHECK-NEXT:    s_waitcnt vmcnt(13) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v6 offset:29
; CHECK-NEXT:    s_waitcnt vmcnt(12) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v7 offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(11) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v8 offset:27
; CHECK-NEXT:    s_waitcnt vmcnt(10) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v9 offset:26
; CHECK-NEXT:    s_waitcnt vmcnt(9) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v10 offset:25
; CHECK-NEXT:    s_waitcnt vmcnt(8) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v11 offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(7) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v12 offset:23
; CHECK-NEXT:    s_waitcnt vmcnt(6) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v13 offset:22
; CHECK-NEXT:    s_waitcnt vmcnt(5) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v14 offset:21
; CHECK-NEXT:    s_waitcnt vmcnt(4) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v15 offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(3) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v16 offset:19
; CHECK-NEXT:    s_waitcnt vmcnt(2) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v17 offset:18
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v18 offset:17
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(15)
; CHECK-NEXT:    flat_store_byte v[2:3], v0 offset:16
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p0.p0.i64(ptr addrspace(0) noundef nonnull align 1 %dst, ptr addrspace(0) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p0_p0_sz32_align_1_1(ptr addrspace(0) align 1 inreg %dst, ptr addrspace(0) align 1 readonly inreg %src) {
; CHECK-LABEL: memmove_p0_p0_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s6
; CHECK-NEXT:    v_mov_b32_e32 v1, s7
; CHECK-NEXT:    s_clause 0x1f
; CHECK-NEXT:    flat_load_ubyte v2, v[0:1] offset:31
; CHECK-NEXT:    flat_load_ubyte v3, v[0:1] offset:30
; CHECK-NEXT:    flat_load_ubyte v4, v[0:1] offset:29
; CHECK-NEXT:    flat_load_ubyte v5, v[0:1] offset:28
; CHECK-NEXT:    flat_load_ubyte v6, v[0:1] offset:27
; CHECK-NEXT:    flat_load_ubyte v7, v[0:1] offset:26
; CHECK-NEXT:    flat_load_ubyte v8, v[0:1] offset:25
; CHECK-NEXT:    flat_load_ubyte v9, v[0:1] offset:24
; CHECK-NEXT:    flat_load_ubyte v10, v[0:1] offset:23
; CHECK-NEXT:    flat_load_ubyte v11, v[0:1] offset:22
; CHECK-NEXT:    flat_load_ubyte v12, v[0:1] offset:21
; CHECK-NEXT:    flat_load_ubyte v13, v[0:1] offset:20
; CHECK-NEXT:    flat_load_ubyte v14, v[0:1] offset:19
; CHECK-NEXT:    flat_load_ubyte v15, v[0:1] offset:18
; CHECK-NEXT:    flat_load_ubyte v16, v[0:1] offset:17
; CHECK-NEXT:    flat_load_ubyte v17, v[0:1] offset:16
; CHECK-NEXT:    flat_load_ubyte v18, v[0:1] offset:15
; CHECK-NEXT:    flat_load_ubyte v19, v[0:1] offset:14
; CHECK-NEXT:    flat_load_ubyte v20, v[0:1] offset:13
; CHECK-NEXT:    flat_load_ubyte v21, v[0:1] offset:12
; CHECK-NEXT:    flat_load_ubyte v22, v[0:1] offset:11
; CHECK-NEXT:    flat_load_ubyte v23, v[0:1] offset:10
; CHECK-NEXT:    flat_load_ubyte v24, v[0:1] offset:9
; CHECK-NEXT:    flat_load_ubyte v25, v[0:1] offset:8
; CHECK-NEXT:    flat_load_ubyte v26, v[0:1] offset:7
; CHECK-NEXT:    flat_load_ubyte v27, v[0:1] offset:6
; CHECK-NEXT:    flat_load_ubyte v28, v[0:1] offset:5
; CHECK-NEXT:    flat_load_ubyte v29, v[0:1] offset:4
; CHECK-NEXT:    flat_load_ubyte v30, v[0:1] offset:3
; CHECK-NEXT:    flat_load_ubyte v31, v[0:1] offset:2
; CHECK-NEXT:    flat_load_ubyte v32, v[0:1] offset:1
; CHECK-NEXT:    flat_load_ubyte v33, v[0:1]
; CHECK-NEXT:    v_mov_b32_e32 v0, s4
; CHECK-NEXT:    v_mov_b32_e32 v1, s5
; CHECK-NEXT:    s_waitcnt vmcnt(31) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v2 offset:31
; CHECK-NEXT:    s_waitcnt vmcnt(30) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v3 offset:30
; CHECK-NEXT:    s_waitcnt vmcnt(29) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v4 offset:29
; CHECK-NEXT:    s_waitcnt vmcnt(28) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v5 offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(27) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v6 offset:27
; CHECK-NEXT:    s_waitcnt vmcnt(26) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v7 offset:26
; CHECK-NEXT:    s_waitcnt vmcnt(25) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v8 offset:25
; CHECK-NEXT:    s_waitcnt vmcnt(24) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v9 offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(23) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v10 offset:23
; CHECK-NEXT:    s_waitcnt vmcnt(22) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v11 offset:22
; CHECK-NEXT:    s_waitcnt vmcnt(21) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v12 offset:21
; CHECK-NEXT:    s_waitcnt vmcnt(20) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v13 offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(19) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v14 offset:19
; CHECK-NEXT:    s_waitcnt vmcnt(18) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v15 offset:18
; CHECK-NEXT:    s_waitcnt vmcnt(17) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v16 offset:17
; CHECK-NEXT:    s_waitcnt vmcnt(16) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v17 offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(15) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v18 offset:15
; CHECK-NEXT:    s_waitcnt vmcnt(14) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v19 offset:14
; CHECK-NEXT:    s_waitcnt vmcnt(13) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v20 offset:13
; CHECK-NEXT:    s_waitcnt vmcnt(12) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v21 offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(11) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v22 offset:11
; CHECK-NEXT:    s_waitcnt vmcnt(10) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v23 offset:10
; CHECK-NEXT:    s_waitcnt vmcnt(9) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v24 offset:9
; CHECK-NEXT:    s_waitcnt vmcnt(8) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v25 offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(7) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v26 offset:7
; CHECK-NEXT:    s_waitcnt vmcnt(6) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v27 offset:6
; CHECK-NEXT:    s_waitcnt vmcnt(5) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v28 offset:5
; CHECK-NEXT:    s_waitcnt vmcnt(4) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v29 offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(3) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v30 offset:3
; CHECK-NEXT:    s_waitcnt vmcnt(2) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v31 offset:2
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v32 offset:1
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(31)
; CHECK-NEXT:    flat_store_byte v[0:1], v33
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p0.p0.i64(ptr addrspace(0) noundef nonnull align 1 %dst, ptr addrspace(0) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p0_p0_sz32_align_2_2(ptr addrspace(0) align 2 inreg %dst, ptr addrspace(0) align 2 readonly inreg %src) {
; CHECK-LABEL: memcpy_p0_p0_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s6
; CHECK-NEXT:    v_mov_b32_e32 v1, s7
; CHECK-NEXT:    s_clause 0xf
; CHECK-NEXT:    flat_load_ushort v2, v[0:1] offset:30
; CHECK-NEXT:    flat_load_ushort v3, v[0:1] offset:28
; CHECK-NEXT:    flat_load_ushort v4, v[0:1] offset:26
; CHECK-NEXT:    flat_load_ushort v5, v[0:1] offset:24
; CHECK-NEXT:    flat_load_ushort v6, v[0:1] offset:22
; CHECK-NEXT:    flat_load_ushort v7, v[0:1] offset:20
; CHECK-NEXT:    flat_load_ushort v8, v[0:1] offset:18
; CHECK-NEXT:    flat_load_ushort v9, v[0:1] offset:16
; CHECK-NEXT:    flat_load_ushort v10, v[0:1] offset:14
; CHECK-NEXT:    flat_load_ushort v11, v[0:1] offset:12
; CHECK-NEXT:    flat_load_ushort v12, v[0:1] offset:10
; CHECK-NEXT:    flat_load_ushort v13, v[0:1] offset:8
; CHECK-NEXT:    flat_load_ushort v14, v[0:1] offset:6
; CHECK-NEXT:    flat_load_ushort v15, v[0:1] offset:4
; CHECK-NEXT:    flat_load_ushort v16, v[0:1] offset:2
; CHECK-NEXT:    flat_load_ushort v17, v[0:1]
; CHECK-NEXT:    v_mov_b32_e32 v0, s4
; CHECK-NEXT:    v_mov_b32_e32 v1, s5
; CHECK-NEXT:    s_waitcnt vmcnt(15) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v2 offset:30
; CHECK-NEXT:    s_waitcnt vmcnt(14) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v3 offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(13) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v4 offset:26
; CHECK-NEXT:    s_waitcnt vmcnt(12) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v5 offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(11) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v6 offset:22
; CHECK-NEXT:    s_waitcnt vmcnt(10) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v7 offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(9) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v8 offset:18
; CHECK-NEXT:    s_waitcnt vmcnt(8) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v9 offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(7) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v10 offset:14
; CHECK-NEXT:    s_waitcnt vmcnt(6) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v11 offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(5) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v12 offset:10
; CHECK-NEXT:    s_waitcnt vmcnt(4) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v13 offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(3) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v14 offset:6
; CHECK-NEXT:    s_waitcnt vmcnt(2) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v15 offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v16 offset:2
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v17
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p0.p0.i64(ptr addrspace(0) noundef nonnull align 2 %dst, ptr addrspace(0) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p0_p0_sz32_align_2_2(ptr addrspace(0) align 2 inreg %dst, ptr addrspace(0) align 2 readonly inreg %src) {
; CHECK-LABEL: memmove_p0_p0_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s6
; CHECK-NEXT:    v_mov_b32_e32 v1, s7
; CHECK-NEXT:    s_clause 0xf
; CHECK-NEXT:    flat_load_ushort v2, v[0:1] offset:30
; CHECK-NEXT:    flat_load_ushort v3, v[0:1] offset:28
; CHECK-NEXT:    flat_load_ushort v4, v[0:1] offset:26
; CHECK-NEXT:    flat_load_ushort v5, v[0:1] offset:24
; CHECK-NEXT:    flat_load_ushort v6, v[0:1] offset:22
; CHECK-NEXT:    flat_load_ushort v7, v[0:1] offset:20
; CHECK-NEXT:    flat_load_ushort v8, v[0:1] offset:18
; CHECK-NEXT:    flat_load_ushort v9, v[0:1] offset:16
; CHECK-NEXT:    flat_load_ushort v10, v[0:1] offset:14
; CHECK-NEXT:    flat_load_ushort v11, v[0:1] offset:12
; CHECK-NEXT:    flat_load_ushort v12, v[0:1] offset:10
; CHECK-NEXT:    flat_load_ushort v13, v[0:1] offset:8
; CHECK-NEXT:    flat_load_ushort v14, v[0:1] offset:6
; CHECK-NEXT:    flat_load_ushort v15, v[0:1] offset:4
; CHECK-NEXT:    flat_load_ushort v16, v[0:1] offset:2
; CHECK-NEXT:    flat_load_ushort v17, v[0:1]
; CHECK-NEXT:    v_mov_b32_e32 v0, s4
; CHECK-NEXT:    v_mov_b32_e32 v1, s5
; CHECK-NEXT:    s_waitcnt vmcnt(15) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v2 offset:30
; CHECK-NEXT:    s_waitcnt vmcnt(14) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v3 offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(13) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v4 offset:26
; CHECK-NEXT:    s_waitcnt vmcnt(12) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v5 offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(11) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v6 offset:22
; CHECK-NEXT:    s_waitcnt vmcnt(10) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v7 offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(9) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v8 offset:18
; CHECK-NEXT:    s_waitcnt vmcnt(8) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v9 offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(7) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v10 offset:14
; CHECK-NEXT:    s_waitcnt vmcnt(6) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v11 offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(5) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v12 offset:10
; CHECK-NEXT:    s_waitcnt vmcnt(4) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v13 offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(3) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v14 offset:6
; CHECK-NEXT:    s_waitcnt vmcnt(2) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v15 offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v16 offset:2
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(15)
; CHECK-NEXT:    flat_store_short v[0:1], v17
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p0.p0.i64(ptr addrspace(0) noundef nonnull align 2 %dst, ptr addrspace(0) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p0_p0_sz32_align_4_4(ptr addrspace(0) align 4 inreg %dst, ptr addrspace(0) align 4 readonly inreg %src) {
; CHECK-LABEL: memcpy_p0_p0_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s6
; CHECK-NEXT:    v_mov_b32_e32 v5, s7
; CHECK-NEXT:    v_mov_b32_e32 v9, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    flat_load_dwordx4 v[0:3], v[4:5] offset:16
; CHECK-NEXT:    flat_load_dwordx4 v[4:7], v[4:5]
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[0:3] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[4:7]
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p0.p0.i64(ptr addrspace(0) noundef nonnull align 4 %dst, ptr addrspace(0) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p0_p0_sz32_align_4_4(ptr addrspace(0) align 4 inreg %dst, ptr addrspace(0) align 4 readonly inreg %src) {
; CHECK-LABEL: memmove_p0_p0_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s6
; CHECK-NEXT:    v_mov_b32_e32 v5, s7
; CHECK-NEXT:    v_mov_b32_e32 v9, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    flat_load_dwordx4 v[0:3], v[4:5] offset:16
; CHECK-NEXT:    flat_load_dwordx4 v[4:7], v[4:5]
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[0:3] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[4:7]
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p0.p0.i64(ptr addrspace(0) noundef nonnull align 4 %dst, ptr addrspace(0) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p0_p0_sz32_align_8_8(ptr addrspace(0) align 8 inreg %dst, ptr addrspace(0) align 8 readonly inreg %src) {
; CHECK-LABEL: memcpy_p0_p0_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s6
; CHECK-NEXT:    v_mov_b32_e32 v5, s7
; CHECK-NEXT:    v_mov_b32_e32 v9, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    flat_load_dwordx4 v[0:3], v[4:5] offset:16
; CHECK-NEXT:    flat_load_dwordx4 v[4:7], v[4:5]
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[0:3] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[4:7]
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p0.p0.i64(ptr addrspace(0) noundef nonnull align 8 %dst, ptr addrspace(0) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p0_p0_sz32_align_8_8(ptr addrspace(0) align 8 inreg %dst, ptr addrspace(0) align 8 readonly inreg %src) {
; CHECK-LABEL: memmove_p0_p0_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s6
; CHECK-NEXT:    v_mov_b32_e32 v5, s7
; CHECK-NEXT:    v_mov_b32_e32 v9, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    flat_load_dwordx4 v[0:3], v[4:5] offset:16
; CHECK-NEXT:    flat_load_dwordx4 v[4:7], v[4:5]
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[0:3] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[4:7]
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p0.p0.i64(ptr addrspace(0) noundef nonnull align 8 %dst, ptr addrspace(0) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p0_p0_sz32_align_16_16(ptr addrspace(0) align 16 inreg %dst, ptr addrspace(0) align 16 readonly inreg %src) {
; CHECK-LABEL: memcpy_p0_p0_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s6
; CHECK-NEXT:    v_mov_b32_e32 v5, s7
; CHECK-NEXT:    v_mov_b32_e32 v9, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    flat_load_dwordx4 v[0:3], v[4:5] offset:16
; CHECK-NEXT:    flat_load_dwordx4 v[4:7], v[4:5]
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[0:3] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[4:7]
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p0.p0.i64(ptr addrspace(0) noundef nonnull align 16 %dst, ptr addrspace(0) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p0_p0_sz32_align_16_16(ptr addrspace(0) align 16 inreg %dst, ptr addrspace(0) align 16 readonly inreg %src) {
; CHECK-LABEL: memmove_p0_p0_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s6
; CHECK-NEXT:    v_mov_b32_e32 v5, s7
; CHECK-NEXT:    v_mov_b32_e32 v9, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    flat_load_dwordx4 v[0:3], v[4:5] offset:16
; CHECK-NEXT:    flat_load_dwordx4 v[4:7], v[4:5]
; CHECK-NEXT:    s_waitcnt vmcnt(1) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[0:3] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(1)
; CHECK-NEXT:    flat_store_dwordx4 v[8:9], v[4:7]
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p0.p0.i64(ptr addrspace(0) noundef nonnull align 16 %dst, ptr addrspace(0) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p1_sz32_align_1_1(ptr addrspace(1) align 1 inreg %dst, ptr addrspace(1) align 1 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p1_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p1.i64(ptr addrspace(1) noundef nonnull align 1 %dst, ptr addrspace(1) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p1_sz32_align_1_1(ptr addrspace(1) align 1 inreg %dst, ptr addrspace(1) align 1 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p1_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p1.i64(ptr addrspace(1) noundef nonnull align 1 %dst, ptr addrspace(1) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p1_sz32_align_2_2(ptr addrspace(1) align 2 inreg %dst, ptr addrspace(1) align 2 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p1_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p1.i64(ptr addrspace(1) noundef nonnull align 2 %dst, ptr addrspace(1) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p1_sz32_align_2_2(ptr addrspace(1) align 2 inreg %dst, ptr addrspace(1) align 2 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p1_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p1.i64(ptr addrspace(1) noundef nonnull align 2 %dst, ptr addrspace(1) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p1_sz32_align_4_4(ptr addrspace(1) align 4 inreg %dst, ptr addrspace(1) align 4 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p1_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p1.i64(ptr addrspace(1) noundef nonnull align 4 %dst, ptr addrspace(1) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p1_sz32_align_4_4(ptr addrspace(1) align 4 inreg %dst, ptr addrspace(1) align 4 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p1_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p1.i64(ptr addrspace(1) noundef nonnull align 4 %dst, ptr addrspace(1) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p1_sz32_align_8_8(ptr addrspace(1) align 8 inreg %dst, ptr addrspace(1) align 8 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p1_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p1.i64(ptr addrspace(1) noundef nonnull align 8 %dst, ptr addrspace(1) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p1_sz32_align_8_8(ptr addrspace(1) align 8 inreg %dst, ptr addrspace(1) align 8 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p1_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p1.i64(ptr addrspace(1) noundef nonnull align 8 %dst, ptr addrspace(1) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p1_sz32_align_16_16(ptr addrspace(1) align 16 inreg %dst, ptr addrspace(1) align 16 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p1_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p1.i64(ptr addrspace(1) noundef nonnull align 16 %dst, ptr addrspace(1) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p1_sz32_align_16_16(ptr addrspace(1) align 16 inreg %dst, ptr addrspace(1) align 16 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p1_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p1.i64(ptr addrspace(1) noundef nonnull align 16 %dst, ptr addrspace(1) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p3_p3_sz32_align_1_1(ptr addrspace(3) align 1 inreg %dst, ptr addrspace(3) align 1 readonly inreg %src) {
; CHECK-LABEL: memcpy_p3_p3_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read2_b64 v[0:3], v4 offset0:2 offset1:3
; CHECK-NEXT:    ds_read2_b64 v[4:7], v4 offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[0:1], v[2:3] offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[4:5], v[6:7] offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p3.p3.i64(ptr addrspace(3) noundef nonnull align 1 %dst, ptr addrspace(3) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p3_p3_sz32_align_1_1(ptr addrspace(3) align 1 inreg %dst, ptr addrspace(3) align 1 readonly inreg %src) {
; CHECK-LABEL: memmove_p3_p3_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read2_b64 v[0:3], v4 offset0:2 offset1:3
; CHECK-NEXT:    ds_read2_b64 v[4:7], v4 offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[0:1], v[2:3] offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[4:5], v[6:7] offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p3.p3.i64(ptr addrspace(3) noundef nonnull align 1 %dst, ptr addrspace(3) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p3_p3_sz32_align_2_2(ptr addrspace(3) align 2 inreg %dst, ptr addrspace(3) align 2 readonly inreg %src) {
; CHECK-LABEL: memcpy_p3_p3_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read2_b64 v[0:3], v4 offset0:2 offset1:3
; CHECK-NEXT:    ds_read2_b64 v[4:7], v4 offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[0:1], v[2:3] offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[4:5], v[6:7] offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p3.p3.i64(ptr addrspace(3) noundef nonnull align 2 %dst, ptr addrspace(3) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p3_p3_sz32_align_2_2(ptr addrspace(3) align 2 inreg %dst, ptr addrspace(3) align 2 readonly inreg %src) {
; CHECK-LABEL: memmove_p3_p3_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read2_b64 v[0:3], v4 offset0:2 offset1:3
; CHECK-NEXT:    ds_read2_b64 v[4:7], v4 offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[0:1], v[2:3] offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[4:5], v[6:7] offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p3.p3.i64(ptr addrspace(3) noundef nonnull align 2 %dst, ptr addrspace(3) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p3_p3_sz32_align_4_4(ptr addrspace(3) align 4 inreg %dst, ptr addrspace(3) align 4 readonly inreg %src) {
; CHECK-LABEL: memcpy_p3_p3_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v6, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read2_b32 v[0:1], v6 offset0:4 offset1:5
; CHECK-NEXT:    ds_read2_b32 v[2:3], v6 offset0:6 offset1:7
; CHECK-NEXT:    ds_read2_b32 v[4:5], v6 offset1:1
; CHECK-NEXT:    ds_read2_b32 v[6:7], v6 offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(3)
; CHECK-NEXT:    ds_write2_b32 v8, v0, v1 offset0:4 offset1:5
; CHECK-NEXT:    s_waitcnt lgkmcnt(3)
; CHECK-NEXT:    ds_write2_b32 v8, v2, v3 offset0:6 offset1:7
; CHECK-NEXT:    s_waitcnt lgkmcnt(3)
; CHECK-NEXT:    ds_write2_b32 v8, v4, v5 offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(3)
; CHECK-NEXT:    ds_write2_b32 v8, v6, v7 offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p3.p3.i64(ptr addrspace(3) noundef nonnull align 4 %dst, ptr addrspace(3) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p3_p3_sz32_align_4_4(ptr addrspace(3) align 4 inreg %dst, ptr addrspace(3) align 4 readonly inreg %src) {
; CHECK-LABEL: memmove_p3_p3_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v6, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read2_b32 v[0:1], v6 offset0:4 offset1:5
; CHECK-NEXT:    ds_read2_b32 v[2:3], v6 offset0:6 offset1:7
; CHECK-NEXT:    ds_read2_b32 v[4:5], v6 offset1:1
; CHECK-NEXT:    ds_read2_b32 v[6:7], v6 offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(3)
; CHECK-NEXT:    ds_write2_b32 v8, v0, v1 offset0:4 offset1:5
; CHECK-NEXT:    s_waitcnt lgkmcnt(3)
; CHECK-NEXT:    ds_write2_b32 v8, v2, v3 offset0:6 offset1:7
; CHECK-NEXT:    s_waitcnt lgkmcnt(3)
; CHECK-NEXT:    ds_write2_b32 v8, v4, v5 offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(3)
; CHECK-NEXT:    ds_write2_b32 v8, v6, v7 offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p3.p3.i64(ptr addrspace(3) noundef nonnull align 4 %dst, ptr addrspace(3) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p3_p3_sz32_align_8_8(ptr addrspace(3) align 8 inreg %dst, ptr addrspace(3) align 8 readonly inreg %src) {
; CHECK-LABEL: memcpy_p3_p3_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read2_b64 v[0:3], v4 offset0:2 offset1:3
; CHECK-NEXT:    ds_read2_b64 v[4:7], v4 offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[0:1], v[2:3] offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[4:5], v[6:7] offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p3.p3.i64(ptr addrspace(3) noundef nonnull align 8 %dst, ptr addrspace(3) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p3_p3_sz32_align_8_8(ptr addrspace(3) align 8 inreg %dst, ptr addrspace(3) align 8 readonly inreg %src) {
; CHECK-LABEL: memmove_p3_p3_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read2_b64 v[0:3], v4 offset0:2 offset1:3
; CHECK-NEXT:    ds_read2_b64 v[4:7], v4 offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[0:1], v[2:3] offset0:2 offset1:3
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write2_b64 v8, v[4:5], v[6:7] offset1:1
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p3.p3.i64(ptr addrspace(3) noundef nonnull align 8 %dst, ptr addrspace(3) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p3_p3_sz32_align_16_16(ptr addrspace(3) align 16 inreg %dst, ptr addrspace(3) align 16 readonly inreg %src) {
; CHECK-LABEL: memcpy_p3_p3_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read_b128 v[0:3], v4 offset:16
; CHECK-NEXT:    ds_read_b128 v[4:7], v4
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write_b128 v8, v[0:3] offset:16
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write_b128 v8, v[4:7]
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p3.p3.i64(ptr addrspace(3) noundef nonnull align 16 %dst, ptr addrspace(3) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p3_p3_sz32_align_16_16(ptr addrspace(3) align 16 inreg %dst, ptr addrspace(3) align 16 readonly inreg %src) {
; CHECK-LABEL: memmove_p3_p3_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v4, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    ds_read_b128 v[0:3], v4 offset:16
; CHECK-NEXT:    ds_read_b128 v[4:7], v4
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write_b128 v8, v[0:3] offset:16
; CHECK-NEXT:    s_waitcnt lgkmcnt(1)
; CHECK-NEXT:    ds_write_b128 v8, v[4:7]
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p3.p3.i64(ptr addrspace(3) noundef nonnull align 16 %dst, ptr addrspace(3) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p4_sz32_align_1_1(ptr addrspace(1) align 1 inreg %dst, ptr addrspace(4) align 1 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p4_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7]
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5]
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5] offset:16
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p4.i64(ptr addrspace(1) noundef nonnull align 1 %dst, ptr addrspace(4) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p4_sz32_align_1_1(ptr addrspace(1) align 1 inreg %dst, ptr addrspace(4) align 1 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p4_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p4.i64(ptr addrspace(1) noundef nonnull align 1 %dst, ptr addrspace(4) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p4_sz32_align_2_2(ptr addrspace(1) align 2 inreg %dst, ptr addrspace(4) align 2 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p4_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7]
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5]
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5] offset:16
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p4.i64(ptr addrspace(1) noundef nonnull align 2 %dst, ptr addrspace(4) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p4_sz32_align_2_2(ptr addrspace(1) align 2 inreg %dst, ptr addrspace(4) align 2 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p4_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_clause 0x1
; CHECK-NEXT:    global_load_dwordx4 v[0:3], v8, s[6:7] offset:16
; CHECK-NEXT:    global_load_dwordx4 v[4:7], v8, s[6:7]
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p4.i64(ptr addrspace(1) noundef nonnull align 2 %dst, ptr addrspace(4) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p4_sz32_align_4_4(ptr addrspace(1) align 4 inreg %dst, ptr addrspace(4) align 4 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p4_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_load_dwordx8 s[8:15], s[6:7], 0x0
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s8
; CHECK-NEXT:    v_mov_b32_e32 v1, s9
; CHECK-NEXT:    v_mov_b32_e32 v2, s10
; CHECK-NEXT:    v_mov_b32_e32 v3, s11
; CHECK-NEXT:    v_mov_b32_e32 v4, s12
; CHECK-NEXT:    v_mov_b32_e32 v5, s13
; CHECK-NEXT:    v_mov_b32_e32 v6, s14
; CHECK-NEXT:    v_mov_b32_e32 v7, s15
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5]
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5] offset:16
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p4.i64(ptr addrspace(1) noundef nonnull align 4 %dst, ptr addrspace(4) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p4_sz32_align_4_4(ptr addrspace(1) align 4 inreg %dst, ptr addrspace(4) align 4 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p4_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_load_dwordx8 s[8:15], s[6:7], 0x0
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s12
; CHECK-NEXT:    v_mov_b32_e32 v1, s13
; CHECK-NEXT:    v_mov_b32_e32 v2, s14
; CHECK-NEXT:    v_mov_b32_e32 v3, s15
; CHECK-NEXT:    v_mov_b32_e32 v4, s8
; CHECK-NEXT:    v_mov_b32_e32 v5, s9
; CHECK-NEXT:    v_mov_b32_e32 v6, s10
; CHECK-NEXT:    v_mov_b32_e32 v7, s11
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p4.i64(ptr addrspace(1) noundef nonnull align 4 %dst, ptr addrspace(4) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p4_sz32_align_8_8(ptr addrspace(1) align 8 inreg %dst, ptr addrspace(4) align 8 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p4_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_load_dwordx8 s[8:15], s[6:7], 0x0
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s8
; CHECK-NEXT:    v_mov_b32_e32 v1, s9
; CHECK-NEXT:    v_mov_b32_e32 v2, s10
; CHECK-NEXT:    v_mov_b32_e32 v3, s11
; CHECK-NEXT:    v_mov_b32_e32 v4, s12
; CHECK-NEXT:    v_mov_b32_e32 v5, s13
; CHECK-NEXT:    v_mov_b32_e32 v6, s14
; CHECK-NEXT:    v_mov_b32_e32 v7, s15
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5]
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5] offset:16
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p4.i64(ptr addrspace(1) noundef nonnull align 8 %dst, ptr addrspace(4) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p4_sz32_align_8_8(ptr addrspace(1) align 8 inreg %dst, ptr addrspace(4) align 8 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p4_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_load_dwordx8 s[8:15], s[6:7], 0x0
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s12
; CHECK-NEXT:    v_mov_b32_e32 v1, s13
; CHECK-NEXT:    v_mov_b32_e32 v2, s14
; CHECK-NEXT:    v_mov_b32_e32 v3, s15
; CHECK-NEXT:    v_mov_b32_e32 v4, s8
; CHECK-NEXT:    v_mov_b32_e32 v5, s9
; CHECK-NEXT:    v_mov_b32_e32 v6, s10
; CHECK-NEXT:    v_mov_b32_e32 v7, s11
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p4.i64(ptr addrspace(1) noundef nonnull align 8 %dst, ptr addrspace(4) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p1_p4_sz32_align_16_16(ptr addrspace(1) align 16 inreg %dst, ptr addrspace(4) align 16 readonly inreg %src) {
; CHECK-LABEL: memcpy_p1_p4_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_load_dwordx8 s[8:15], s[6:7], 0x0
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s8
; CHECK-NEXT:    v_mov_b32_e32 v1, s9
; CHECK-NEXT:    v_mov_b32_e32 v2, s10
; CHECK-NEXT:    v_mov_b32_e32 v3, s11
; CHECK-NEXT:    v_mov_b32_e32 v4, s12
; CHECK-NEXT:    v_mov_b32_e32 v5, s13
; CHECK-NEXT:    v_mov_b32_e32 v6, s14
; CHECK-NEXT:    v_mov_b32_e32 v7, s15
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5]
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5] offset:16
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p1.p4.i64(ptr addrspace(1) noundef nonnull align 16 %dst, ptr addrspace(4) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p1_p4_sz32_align_16_16(ptr addrspace(1) align 16 inreg %dst, ptr addrspace(4) align 16 readonly inreg %src) {
; CHECK-LABEL: memmove_p1_p4_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_load_dwordx8 s[8:15], s[6:7], 0x0
; CHECK-NEXT:    v_mov_b32_e32 v8, 0
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s12
; CHECK-NEXT:    v_mov_b32_e32 v1, s13
; CHECK-NEXT:    v_mov_b32_e32 v2, s14
; CHECK-NEXT:    v_mov_b32_e32 v3, s15
; CHECK-NEXT:    v_mov_b32_e32 v4, s8
; CHECK-NEXT:    v_mov_b32_e32 v5, s9
; CHECK-NEXT:    v_mov_b32_e32 v6, s10
; CHECK-NEXT:    v_mov_b32_e32 v7, s11
; CHECK-NEXT:    global_store_dwordx4 v8, v[0:3], s[4:5] offset:16
; CHECK-NEXT:    global_store_dwordx4 v8, v[4:7], s[4:5]
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p1.p4.i64(ptr addrspace(1) noundef nonnull align 16 %dst, ptr addrspace(4) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p5_p5_sz32_align_1_1(ptr addrspace(5) align 1 inreg %dst, ptr addrspace(5) align 1 readonly inreg %src) {
; CHECK-LABEL: memcpy_p5_p5_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v17, s4
; CHECK-NEXT:    s_clause 0x11
; CHECK-NEXT:    buffer_load_ubyte v1, v0, s[0:3], 0 offen offset:15
; CHECK-NEXT:    buffer_load_ubyte v2, v0, s[0:3], 0 offen offset:14
; CHECK-NEXT:    buffer_load_ubyte v3, v0, s[0:3], 0 offen offset:13
; CHECK-NEXT:    buffer_load_ubyte v4, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    buffer_load_ubyte v5, v0, s[0:3], 0 offen offset:11
; CHECK-NEXT:    buffer_load_ubyte v6, v0, s[0:3], 0 offen offset:10
; CHECK-NEXT:    buffer_load_ubyte v7, v0, s[0:3], 0 offen offset:9
; CHECK-NEXT:    buffer_load_ubyte v8, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_ubyte v9, v0, s[0:3], 0 offen offset:7
; CHECK-NEXT:    buffer_load_ubyte v10, v0, s[0:3], 0 offen offset:6
; CHECK-NEXT:    buffer_load_ubyte v11, v0, s[0:3], 0 offen offset:5
; CHECK-NEXT:    buffer_load_ubyte v12, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_ubyte v13, v0, s[0:3], 0 offen offset:3
; CHECK-NEXT:    buffer_load_ubyte v14, v0, s[0:3], 0 offen offset:2
; CHECK-NEXT:    buffer_load_ubyte v15, v0, s[0:3], 0 offen offset:1
; CHECK-NEXT:    buffer_load_ubyte v16, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_ubyte v18, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_ubyte v19, v0, s[0:3], 0 offen offset:17
; CHECK-NEXT:    s_waitcnt vmcnt(17)
; CHECK-NEXT:    buffer_store_byte v1, v17, s[0:3], 0 offen offset:15
; CHECK-NEXT:    s_waitcnt vmcnt(16)
; CHECK-NEXT:    buffer_store_byte v2, v17, s[0:3], 0 offen offset:14
; CHECK-NEXT:    s_waitcnt vmcnt(15)
; CHECK-NEXT:    buffer_store_byte v3, v17, s[0:3], 0 offen offset:13
; CHECK-NEXT:    s_waitcnt vmcnt(14)
; CHECK-NEXT:    buffer_store_byte v4, v17, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(13)
; CHECK-NEXT:    buffer_store_byte v5, v17, s[0:3], 0 offen offset:11
; CHECK-NEXT:    s_waitcnt vmcnt(12)
; CHECK-NEXT:    buffer_store_byte v6, v17, s[0:3], 0 offen offset:10
; CHECK-NEXT:    s_waitcnt vmcnt(11)
; CHECK-NEXT:    buffer_store_byte v7, v17, s[0:3], 0 offen offset:9
; CHECK-NEXT:    s_waitcnt vmcnt(10)
; CHECK-NEXT:    buffer_store_byte v8, v17, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(9)
; CHECK-NEXT:    buffer_store_byte v9, v17, s[0:3], 0 offen offset:7
; CHECK-NEXT:    s_waitcnt vmcnt(8)
; CHECK-NEXT:    buffer_store_byte v10, v17, s[0:3], 0 offen offset:6
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_byte v11, v17, s[0:3], 0 offen offset:5
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_byte v12, v17, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_byte v13, v17, s[0:3], 0 offen offset:3
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_byte v14, v17, s[0:3], 0 offen offset:2
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_byte v15, v17, s[0:3], 0 offen offset:1
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_byte v16, v17, s[0:3], 0 offen
; CHECK-NEXT:    s_clause 0xd
; CHECK-NEXT:    buffer_load_ubyte v1, v0, s[0:3], 0 offen offset:31
; CHECK-NEXT:    buffer_load_ubyte v2, v0, s[0:3], 0 offen offset:30
; CHECK-NEXT:    buffer_load_ubyte v3, v0, s[0:3], 0 offen offset:29
; CHECK-NEXT:    buffer_load_ubyte v4, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_ubyte v5, v0, s[0:3], 0 offen offset:27
; CHECK-NEXT:    buffer_load_ubyte v6, v0, s[0:3], 0 offen offset:26
; CHECK-NEXT:    buffer_load_ubyte v7, v0, s[0:3], 0 offen offset:25
; CHECK-NEXT:    buffer_load_ubyte v8, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_ubyte v9, v0, s[0:3], 0 offen offset:23
; CHECK-NEXT:    buffer_load_ubyte v10, v0, s[0:3], 0 offen offset:22
; CHECK-NEXT:    buffer_load_ubyte v11, v0, s[0:3], 0 offen offset:21
; CHECK-NEXT:    buffer_load_ubyte v12, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_ubyte v13, v0, s[0:3], 0 offen offset:19
; CHECK-NEXT:    buffer_load_ubyte v0, v0, s[0:3], 0 offen offset:18
; CHECK-NEXT:    s_waitcnt vmcnt(14)
; CHECK-NEXT:    buffer_store_byte v19, v17, s[0:3], 0 offen offset:17
; CHECK-NEXT:    s_waitcnt vmcnt(13)
; CHECK-NEXT:    buffer_store_byte v1, v17, s[0:3], 0 offen offset:31
; CHECK-NEXT:    s_waitcnt vmcnt(12)
; CHECK-NEXT:    buffer_store_byte v2, v17, s[0:3], 0 offen offset:30
; CHECK-NEXT:    s_waitcnt vmcnt(11)
; CHECK-NEXT:    buffer_store_byte v3, v17, s[0:3], 0 offen offset:29
; CHECK-NEXT:    s_waitcnt vmcnt(10)
; CHECK-NEXT:    buffer_store_byte v4, v17, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(9)
; CHECK-NEXT:    buffer_store_byte v5, v17, s[0:3], 0 offen offset:27
; CHECK-NEXT:    s_waitcnt vmcnt(8)
; CHECK-NEXT:    buffer_store_byte v6, v17, s[0:3], 0 offen offset:26
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_byte v7, v17, s[0:3], 0 offen offset:25
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_byte v8, v17, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_byte v9, v17, s[0:3], 0 offen offset:23
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_byte v10, v17, s[0:3], 0 offen offset:22
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_byte v11, v17, s[0:3], 0 offen offset:21
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_byte v12, v17, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_byte v13, v17, s[0:3], 0 offen offset:19
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_byte v0, v17, s[0:3], 0 offen offset:18
; CHECK-NEXT:    buffer_store_byte v18, v17, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p5.p5.i64(ptr addrspace(5) noundef nonnull align 1 %dst, ptr addrspace(5) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p5_p5_sz32_align_1_1(ptr addrspace(5) align 1 inreg %dst, ptr addrspace(5) align 1 readonly inreg %src) {
; CHECK-LABEL: memmove_p5_p5_sz32_align_1_1:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v32, s4
; CHECK-NEXT:    s_clause 0x1f
; CHECK-NEXT:    buffer_load_ubyte v1, v0, s[0:3], 0 offen offset:31
; CHECK-NEXT:    buffer_load_ubyte v2, v0, s[0:3], 0 offen offset:30
; CHECK-NEXT:    buffer_load_ubyte v3, v0, s[0:3], 0 offen offset:29
; CHECK-NEXT:    buffer_load_ubyte v4, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_ubyte v5, v0, s[0:3], 0 offen offset:27
; CHECK-NEXT:    buffer_load_ubyte v6, v0, s[0:3], 0 offen offset:26
; CHECK-NEXT:    buffer_load_ubyte v7, v0, s[0:3], 0 offen offset:25
; CHECK-NEXT:    buffer_load_ubyte v8, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_ubyte v9, v0, s[0:3], 0 offen offset:23
; CHECK-NEXT:    buffer_load_ubyte v10, v0, s[0:3], 0 offen offset:22
; CHECK-NEXT:    buffer_load_ubyte v11, v0, s[0:3], 0 offen offset:21
; CHECK-NEXT:    buffer_load_ubyte v12, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_ubyte v13, v0, s[0:3], 0 offen offset:19
; CHECK-NEXT:    buffer_load_ubyte v14, v0, s[0:3], 0 offen offset:18
; CHECK-NEXT:    buffer_load_ubyte v15, v0, s[0:3], 0 offen offset:17
; CHECK-NEXT:    buffer_load_ubyte v16, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_ubyte v17, v0, s[0:3], 0 offen offset:15
; CHECK-NEXT:    buffer_load_ubyte v18, v0, s[0:3], 0 offen offset:14
; CHECK-NEXT:    buffer_load_ubyte v19, v0, s[0:3], 0 offen offset:13
; CHECK-NEXT:    buffer_load_ubyte v20, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    buffer_load_ubyte v21, v0, s[0:3], 0 offen offset:11
; CHECK-NEXT:    buffer_load_ubyte v22, v0, s[0:3], 0 offen offset:10
; CHECK-NEXT:    buffer_load_ubyte v23, v0, s[0:3], 0 offen offset:9
; CHECK-NEXT:    buffer_load_ubyte v24, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_ubyte v25, v0, s[0:3], 0 offen offset:7
; CHECK-NEXT:    buffer_load_ubyte v26, v0, s[0:3], 0 offen offset:6
; CHECK-NEXT:    buffer_load_ubyte v27, v0, s[0:3], 0 offen offset:5
; CHECK-NEXT:    buffer_load_ubyte v28, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_ubyte v29, v0, s[0:3], 0 offen offset:3
; CHECK-NEXT:    buffer_load_ubyte v30, v0, s[0:3], 0 offen offset:2
; CHECK-NEXT:    buffer_load_ubyte v31, v0, s[0:3], 0 offen offset:1
; CHECK-NEXT:    buffer_load_ubyte v0, v0, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(31)
; CHECK-NEXT:    buffer_store_byte v1, v32, s[0:3], 0 offen offset:31
; CHECK-NEXT:    s_waitcnt vmcnt(30)
; CHECK-NEXT:    buffer_store_byte v2, v32, s[0:3], 0 offen offset:30
; CHECK-NEXT:    s_waitcnt vmcnt(29)
; CHECK-NEXT:    buffer_store_byte v3, v32, s[0:3], 0 offen offset:29
; CHECK-NEXT:    s_waitcnt vmcnt(28)
; CHECK-NEXT:    buffer_store_byte v4, v32, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(27)
; CHECK-NEXT:    buffer_store_byte v5, v32, s[0:3], 0 offen offset:27
; CHECK-NEXT:    s_waitcnt vmcnt(26)
; CHECK-NEXT:    buffer_store_byte v6, v32, s[0:3], 0 offen offset:26
; CHECK-NEXT:    s_waitcnt vmcnt(25)
; CHECK-NEXT:    buffer_store_byte v7, v32, s[0:3], 0 offen offset:25
; CHECK-NEXT:    s_waitcnt vmcnt(24)
; CHECK-NEXT:    buffer_store_byte v8, v32, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(23)
; CHECK-NEXT:    buffer_store_byte v9, v32, s[0:3], 0 offen offset:23
; CHECK-NEXT:    s_waitcnt vmcnt(22)
; CHECK-NEXT:    buffer_store_byte v10, v32, s[0:3], 0 offen offset:22
; CHECK-NEXT:    s_waitcnt vmcnt(21)
; CHECK-NEXT:    buffer_store_byte v11, v32, s[0:3], 0 offen offset:21
; CHECK-NEXT:    s_waitcnt vmcnt(20)
; CHECK-NEXT:    buffer_store_byte v12, v32, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(19)
; CHECK-NEXT:    buffer_store_byte v13, v32, s[0:3], 0 offen offset:19
; CHECK-NEXT:    s_waitcnt vmcnt(18)
; CHECK-NEXT:    buffer_store_byte v14, v32, s[0:3], 0 offen offset:18
; CHECK-NEXT:    s_waitcnt vmcnt(17)
; CHECK-NEXT:    buffer_store_byte v15, v32, s[0:3], 0 offen offset:17
; CHECK-NEXT:    s_waitcnt vmcnt(16)
; CHECK-NEXT:    buffer_store_byte v16, v32, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(15)
; CHECK-NEXT:    buffer_store_byte v17, v32, s[0:3], 0 offen offset:15
; CHECK-NEXT:    s_waitcnt vmcnt(14)
; CHECK-NEXT:    buffer_store_byte v18, v32, s[0:3], 0 offen offset:14
; CHECK-NEXT:    s_waitcnt vmcnt(13)
; CHECK-NEXT:    buffer_store_byte v19, v32, s[0:3], 0 offen offset:13
; CHECK-NEXT:    s_waitcnt vmcnt(12)
; CHECK-NEXT:    buffer_store_byte v20, v32, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(11)
; CHECK-NEXT:    buffer_store_byte v21, v32, s[0:3], 0 offen offset:11
; CHECK-NEXT:    s_waitcnt vmcnt(10)
; CHECK-NEXT:    buffer_store_byte v22, v32, s[0:3], 0 offen offset:10
; CHECK-NEXT:    s_waitcnt vmcnt(9)
; CHECK-NEXT:    buffer_store_byte v23, v32, s[0:3], 0 offen offset:9
; CHECK-NEXT:    s_waitcnt vmcnt(8)
; CHECK-NEXT:    buffer_store_byte v24, v32, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_byte v25, v32, s[0:3], 0 offen offset:7
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_byte v26, v32, s[0:3], 0 offen offset:6
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_byte v27, v32, s[0:3], 0 offen offset:5
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_byte v28, v32, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_byte v29, v32, s[0:3], 0 offen offset:3
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_byte v30, v32, s[0:3], 0 offen offset:2
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_byte v31, v32, s[0:3], 0 offen offset:1
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_byte v0, v32, s[0:3], 0 offen
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p5.p5.i64(ptr addrspace(5) noundef nonnull align 1 %dst, ptr addrspace(5) noundef nonnull align 1 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p5_p5_sz32_align_2_2(ptr addrspace(5) align 2 inreg %dst, ptr addrspace(5) align 2 readonly inreg %src) {
; CHECK-LABEL: memcpy_p5_p5_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v16, s4
; CHECK-NEXT:    s_clause 0xf
; CHECK-NEXT:    buffer_load_ushort v1, v0, s[0:3], 0 offen offset:30
; CHECK-NEXT:    buffer_load_ushort v2, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_ushort v3, v0, s[0:3], 0 offen offset:26
; CHECK-NEXT:    buffer_load_ushort v4, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_ushort v5, v0, s[0:3], 0 offen offset:22
; CHECK-NEXT:    buffer_load_ushort v6, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_ushort v7, v0, s[0:3], 0 offen offset:18
; CHECK-NEXT:    buffer_load_ushort v8, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_ushort v9, v0, s[0:3], 0 offen offset:14
; CHECK-NEXT:    buffer_load_ushort v10, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    buffer_load_ushort v11, v0, s[0:3], 0 offen offset:10
; CHECK-NEXT:    buffer_load_ushort v12, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_ushort v13, v0, s[0:3], 0 offen offset:6
; CHECK-NEXT:    buffer_load_ushort v14, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_ushort v15, v0, s[0:3], 0 offen offset:2
; CHECK-NEXT:    buffer_load_ushort v0, v0, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(15)
; CHECK-NEXT:    buffer_store_short v1, v16, s[0:3], 0 offen offset:30
; CHECK-NEXT:    s_waitcnt vmcnt(14)
; CHECK-NEXT:    buffer_store_short v2, v16, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(13)
; CHECK-NEXT:    buffer_store_short v3, v16, s[0:3], 0 offen offset:26
; CHECK-NEXT:    s_waitcnt vmcnt(12)
; CHECK-NEXT:    buffer_store_short v4, v16, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(11)
; CHECK-NEXT:    buffer_store_short v5, v16, s[0:3], 0 offen offset:22
; CHECK-NEXT:    s_waitcnt vmcnt(10)
; CHECK-NEXT:    buffer_store_short v6, v16, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(9)
; CHECK-NEXT:    buffer_store_short v7, v16, s[0:3], 0 offen offset:18
; CHECK-NEXT:    s_waitcnt vmcnt(8)
; CHECK-NEXT:    buffer_store_short v8, v16, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_short v9, v16, s[0:3], 0 offen offset:14
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_short v10, v16, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_short v11, v16, s[0:3], 0 offen offset:10
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_short v12, v16, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_short v13, v16, s[0:3], 0 offen offset:6
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_short v14, v16, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_short v15, v16, s[0:3], 0 offen offset:2
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_short v0, v16, s[0:3], 0 offen
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p5.p5.i64(ptr addrspace(5) noundef nonnull align 2 %dst, ptr addrspace(5) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p5_p5_sz32_align_2_2(ptr addrspace(5) align 2 inreg %dst, ptr addrspace(5) align 2 readonly inreg %src) {
; CHECK-LABEL: memmove_p5_p5_sz32_align_2_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v16, s4
; CHECK-NEXT:    s_clause 0xf
; CHECK-NEXT:    buffer_load_ushort v1, v0, s[0:3], 0 offen offset:30
; CHECK-NEXT:    buffer_load_ushort v2, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_ushort v3, v0, s[0:3], 0 offen offset:26
; CHECK-NEXT:    buffer_load_ushort v4, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_ushort v5, v0, s[0:3], 0 offen offset:22
; CHECK-NEXT:    buffer_load_ushort v6, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_ushort v7, v0, s[0:3], 0 offen offset:18
; CHECK-NEXT:    buffer_load_ushort v8, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_ushort v9, v0, s[0:3], 0 offen offset:14
; CHECK-NEXT:    buffer_load_ushort v10, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    buffer_load_ushort v11, v0, s[0:3], 0 offen offset:10
; CHECK-NEXT:    buffer_load_ushort v12, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_ushort v13, v0, s[0:3], 0 offen offset:6
; CHECK-NEXT:    buffer_load_ushort v14, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_ushort v15, v0, s[0:3], 0 offen offset:2
; CHECK-NEXT:    buffer_load_ushort v0, v0, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(15)
; CHECK-NEXT:    buffer_store_short v1, v16, s[0:3], 0 offen offset:30
; CHECK-NEXT:    s_waitcnt vmcnt(14)
; CHECK-NEXT:    buffer_store_short v2, v16, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(13)
; CHECK-NEXT:    buffer_store_short v3, v16, s[0:3], 0 offen offset:26
; CHECK-NEXT:    s_waitcnt vmcnt(12)
; CHECK-NEXT:    buffer_store_short v4, v16, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(11)
; CHECK-NEXT:    buffer_store_short v5, v16, s[0:3], 0 offen offset:22
; CHECK-NEXT:    s_waitcnt vmcnt(10)
; CHECK-NEXT:    buffer_store_short v6, v16, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(9)
; CHECK-NEXT:    buffer_store_short v7, v16, s[0:3], 0 offen offset:18
; CHECK-NEXT:    s_waitcnt vmcnt(8)
; CHECK-NEXT:    buffer_store_short v8, v16, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_short v9, v16, s[0:3], 0 offen offset:14
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_short v10, v16, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_short v11, v16, s[0:3], 0 offen offset:10
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_short v12, v16, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_short v13, v16, s[0:3], 0 offen offset:6
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_short v14, v16, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_short v15, v16, s[0:3], 0 offen offset:2
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_short v0, v16, s[0:3], 0 offen
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p5.p5.i64(ptr addrspace(5) noundef nonnull align 2 %dst, ptr addrspace(5) noundef nonnull align 2 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p5_p5_sz32_align_4_4(ptr addrspace(5) align 4 inreg %dst, ptr addrspace(5) align 4 readonly inreg %src) {
; CHECK-LABEL: memcpy_p5_p5_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x7
; CHECK-NEXT:    buffer_load_dword v1, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_dword v2, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_dword v3, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_dword v4, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_dword v5, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_dword v6, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_dword v7, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_dword v0, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_dword v1, v8, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_dword v2, v8, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_dword v3, v8, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_dword v4, v8, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_dword v5, v8, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_dword v6, v8, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_dword v7, v8, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_dword v0, v8, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p5.p5.i64(ptr addrspace(5) noundef nonnull align 4 %dst, ptr addrspace(5) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p5_p5_sz32_align_4_4(ptr addrspace(5) align 4 inreg %dst, ptr addrspace(5) align 4 readonly inreg %src) {
; CHECK-LABEL: memmove_p5_p5_sz32_align_4_4:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x7
; CHECK-NEXT:    buffer_load_dword v1, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_dword v2, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_dword v3, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_dword v4, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_dword v5, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_dword v6, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_dword v7, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_dword v0, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_dword v1, v8, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_dword v2, v8, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_dword v3, v8, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_dword v4, v8, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_dword v5, v8, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_dword v6, v8, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_dword v7, v8, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_dword v0, v8, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p5.p5.i64(ptr addrspace(5) noundef nonnull align 4 %dst, ptr addrspace(5) noundef nonnull align 4 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p5_p5_sz32_align_8_8(ptr addrspace(5) align 8 inreg %dst, ptr addrspace(5) align 8 readonly inreg %src) {
; CHECK-LABEL: memcpy_p5_p5_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x7
; CHECK-NEXT:    buffer_load_dword v1, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_dword v2, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_dword v3, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_dword v4, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_dword v5, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_dword v6, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_dword v7, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_dword v0, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_dword v1, v8, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_dword v2, v8, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_dword v3, v8, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_dword v4, v8, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_dword v5, v8, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_dword v6, v8, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_dword v7, v8, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_dword v0, v8, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p5.p5.i64(ptr addrspace(5) noundef nonnull align 8 %dst, ptr addrspace(5) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p5_p5_sz32_align_8_8(ptr addrspace(5) align 8 inreg %dst, ptr addrspace(5) align 8 readonly inreg %src) {
; CHECK-LABEL: memmove_p5_p5_sz32_align_8_8:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x7
; CHECK-NEXT:    buffer_load_dword v1, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_dword v2, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_dword v3, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_dword v4, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_dword v5, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_dword v6, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_dword v7, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_dword v0, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_dword v1, v8, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_dword v2, v8, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_dword v3, v8, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_dword v4, v8, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_dword v5, v8, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_dword v6, v8, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_dword v7, v8, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_dword v0, v8, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p5.p5.i64(ptr addrspace(5) noundef nonnull align 8 %dst, ptr addrspace(5) noundef nonnull align 8 %src, i64 32, i1 false)
  ret void
}

define void @memcpy_p5_p5_sz32_align_16_16(ptr addrspace(5) align 16 inreg %dst, ptr addrspace(5) align 16 readonly inreg %src) {
; CHECK-LABEL: memcpy_p5_p5_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x7
; CHECK-NEXT:    buffer_load_dword v1, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_dword v2, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_dword v3, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_dword v4, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_dword v5, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_dword v6, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_dword v7, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_dword v0, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_dword v1, v8, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_dword v2, v8, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_dword v3, v8, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_dword v4, v8, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_dword v5, v8, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_dword v6, v8, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_dword v7, v8, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_dword v0, v8, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memcpy.p5.p5.i64(ptr addrspace(5) noundef nonnull align 16 %dst, ptr addrspace(5) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

define void @memmove_p5_p5_sz32_align_16_16(ptr addrspace(5) align 16 inreg %dst, ptr addrspace(5) align 16 readonly inreg %src) {
; CHECK-LABEL: memmove_p5_p5_sz32_align_16_16:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v0, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    s_clause 0x7
; CHECK-NEXT:    buffer_load_dword v1, v0, s[0:3], 0 offen offset:16
; CHECK-NEXT:    buffer_load_dword v2, v0, s[0:3], 0 offen offset:20
; CHECK-NEXT:    buffer_load_dword v3, v0, s[0:3], 0 offen offset:24
; CHECK-NEXT:    buffer_load_dword v4, v0, s[0:3], 0 offen offset:28
; CHECK-NEXT:    buffer_load_dword v5, v0, s[0:3], 0 offen
; CHECK-NEXT:    buffer_load_dword v6, v0, s[0:3], 0 offen offset:4
; CHECK-NEXT:    buffer_load_dword v7, v0, s[0:3], 0 offen offset:8
; CHECK-NEXT:    buffer_load_dword v0, v0, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_waitcnt vmcnt(7)
; CHECK-NEXT:    buffer_store_dword v1, v8, s[0:3], 0 offen offset:16
; CHECK-NEXT:    s_waitcnt vmcnt(6)
; CHECK-NEXT:    buffer_store_dword v2, v8, s[0:3], 0 offen offset:20
; CHECK-NEXT:    s_waitcnt vmcnt(5)
; CHECK-NEXT:    buffer_store_dword v3, v8, s[0:3], 0 offen offset:24
; CHECK-NEXT:    s_waitcnt vmcnt(4)
; CHECK-NEXT:    buffer_store_dword v4, v8, s[0:3], 0 offen offset:28
; CHECK-NEXT:    s_waitcnt vmcnt(3)
; CHECK-NEXT:    buffer_store_dword v5, v8, s[0:3], 0 offen
; CHECK-NEXT:    s_waitcnt vmcnt(2)
; CHECK-NEXT:    buffer_store_dword v6, v8, s[0:3], 0 offen offset:4
; CHECK-NEXT:    s_waitcnt vmcnt(1)
; CHECK-NEXT:    buffer_store_dword v7, v8, s[0:3], 0 offen offset:8
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_dword v0, v8, s[0:3], 0 offen offset:12
; CHECK-NEXT:    s_setpc_b64 s[30:31]
entry:
  tail call void @llvm.memmove.p5.p5.i64(ptr addrspace(5) noundef nonnull align 16 %dst, ptr addrspace(5) noundef nonnull align 16 %src, i64 32, i1 false)
  ret void
}

declare void @llvm.memcpy.p0.p0.i64(ptr addrspace(0) noalias nocapture writeonly, ptr addrspace(0) noalias nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memcpy.p1.p1.i64(ptr addrspace(1) noalias nocapture writeonly, ptr addrspace(1) noalias nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memcpy.p3.p3.i64(ptr addrspace(3) noalias nocapture writeonly, ptr addrspace(3) noalias nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memcpy.p1.p4.i64(ptr addrspace(1) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memcpy.p5.p5.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(5) noalias nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memmove.p0.p0.i64(ptr addrspace(0) nocapture writeonly, ptr addrspace(0) nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memmove.p1.p1.i64(ptr addrspace(1) nocapture writeonly, ptr addrspace(1) nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memmove.p3.p3.i64(ptr addrspace(3) nocapture writeonly, ptr addrspace(3) nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memmove.p1.p4.i64(ptr addrspace(1) nocapture writeonly, ptr addrspace(4) nocapture readonly, i64, i1 immarg) #2
declare void @llvm.memmove.p5.p5.i64(ptr addrspace(5) nocapture writeonly, ptr addrspace(5) nocapture readonly, i64, i1 immarg) #2

attributes #0 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) }

