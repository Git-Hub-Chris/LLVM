; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 3
; RUN: opt -passes=vector-widen -vw-override-target-consider-to-widen=1 -S %s 2>&1 | FileCheck %s


define void @sext(<8 x i8> %a, <8 x i8> %b, ptr %ptr, ptr %ptr1) {
; CHECK-LABEL: define void @sext(
; CHECK-SAME: <8 x i8> [[A:%.*]], <8 x i8> [[B:%.*]], ptr [[PTR:%.*]], ptr [[PTR1:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = call <16 x i8> @llvm.vector.insert.v16i8.v8i8(<16 x i8> undef, <8 x i8> [[B]], i64 0)
; CHECK-NEXT:    [[TMP1:%.*]] = call <16 x i8> @llvm.vector.insert.v16i8.v8i8(<16 x i8> [[TMP0]], <8 x i8> [[A]], i64 8)
; CHECK-NEXT:    [[TMP2:%.*]] = sext <16 x i8> [[TMP1]] to <16 x i64>
; CHECK-NEXT:    [[TMP3:%.*]] = call <8 x i64> @llvm.vector.extract.v8i64.v16i64(<16 x i64> [[TMP2]], i64 0)
; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i64> @llvm.vector.extract.v8i64.v16i64(<16 x i64> [[TMP2]], i64 8)
; CHECK-NEXT:    store <8 x i64> [[TMP4]], ptr [[PTR]], align 16
; CHECK-NEXT:    store <8 x i64> [[TMP3]], ptr [[PTR1]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %0 = sext <8 x i8> %a to <8 x i64>
  %1 = sext <8 x i8> %b to <8 x i64>
  store <8 x i64> %0, ptr %ptr, align 16
  store <8 x i64> %1, ptr %ptr1, align 16
  ret void
}

define void @zext(<8 x i8> %a, <8 x i8> %b, ptr %ptr, ptr %ptr1) {
; CHECK-LABEL: define void @zext(
; CHECK-SAME: <8 x i8> [[A:%.*]], <8 x i8> [[B:%.*]], ptr [[PTR:%.*]], ptr [[PTR1:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = call <16 x i8> @llvm.vector.insert.v16i8.v8i8(<16 x i8> undef, <8 x i8> [[B]], i64 0)
; CHECK-NEXT:    [[TMP1:%.*]] = call <16 x i8> @llvm.vector.insert.v16i8.v8i8(<16 x i8> [[TMP0]], <8 x i8> [[A]], i64 8)
; CHECK-NEXT:    [[TMP2:%.*]] = zext <16 x i8> [[TMP1]] to <16 x i64>
; CHECK-NEXT:    [[TMP3:%.*]] = call <8 x i64> @llvm.vector.extract.v8i64.v16i64(<16 x i64> [[TMP2]], i64 0)
; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i64> @llvm.vector.extract.v8i64.v16i64(<16 x i64> [[TMP2]], i64 8)
; CHECK-NEXT:    store <8 x i64> [[TMP4]], ptr [[PTR]], align 16
; CHECK-NEXT:    store <8 x i64> [[TMP3]], ptr [[PTR1]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %0 = zext <8 x i8> %a to <8 x i64>
  %1 = zext <8 x i8> %b to <8 x i64>
  store <8 x i64> %0, ptr %ptr, align 16
  store <8 x i64> %1, ptr %ptr1, align 16
  ret void
}

define void @trunc(<8 x i64> %a, <8 x i64> %b, ptr %ptr, ptr %ptr1) {
; CHECK-LABEL: define void @trunc(
; CHECK-SAME: <8 x i64> [[A:%.*]], <8 x i64> [[B:%.*]], ptr [[PTR:%.*]], ptr [[PTR1:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = call <16 x i64> @llvm.vector.insert.v16i64.v8i64(<16 x i64> undef, <8 x i64> [[B]], i64 0)
; CHECK-NEXT:    [[TMP1:%.*]] = call <16 x i64> @llvm.vector.insert.v16i64.v8i64(<16 x i64> [[TMP0]], <8 x i64> [[A]], i64 8)
; CHECK-NEXT:    [[TMP2:%.*]] = trunc <16 x i64> [[TMP1]] to <16 x i8>
; CHECK-NEXT:    [[TMP3:%.*]] = call <8 x i8> @llvm.vector.extract.v8i8.v16i8(<16 x i8> [[TMP2]], i64 0)
; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i8> @llvm.vector.extract.v8i8.v16i8(<16 x i8> [[TMP2]], i64 8)
; CHECK-NEXT:    store <8 x i8> [[TMP4]], ptr [[PTR]], align 16
; CHECK-NEXT:    store <8 x i8> [[TMP3]], ptr [[PTR1]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %0 = trunc <8 x i64> %a to <8 x i8>
  %1 = trunc <8 x i64> %b to <8 x i8>
  store <8 x i8> %0, ptr %ptr, align 16
  store <8 x i8> %1, ptr %ptr1, align 16
  ret void
}

