; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 3
; RUN: opt -passes=vector-widen -vw-override-target-consider-to-widen=1 -S %s 2>&1 | FileCheck %s


define void @bitcast1(<8 x i64> %a, <8 x i64> %b, ptr %ptr, ptr %ptr1) {
; CHECK-LABEL: define void @bitcast1(
; CHECK-SAME: <8 x i64> [[A:%.*]], <8 x i64> [[B:%.*]], ptr [[PTR:%.*]], ptr [[PTR1:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = call <16 x i64> @llvm.vector.insert.v16i64.v8i64(<16 x i64> undef, <8 x i64> [[B]], i64 0)
; CHECK-NEXT:    [[TMP1:%.*]] = call <16 x i64> @llvm.vector.insert.v16i64.v8i64(<16 x i64> [[TMP0]], <8 x i64> [[A]], i64 8)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast <16 x i64> [[TMP1]] to <32 x i32>
; CHECK-NEXT:    [[TMP3:%.*]] = call <16 x i32> @llvm.vector.extract.v16i32.v32i32(<32 x i32> [[TMP2]], i64 0)
; CHECK-NEXT:    [[TMP4:%.*]] = call <16 x i32> @llvm.vector.extract.v16i32.v32i32(<32 x i32> [[TMP2]], i64 16)
; CHECK-NEXT:    store <16 x i32> [[TMP4]], ptr [[PTR]], align 16
; CHECK-NEXT:    store <16 x i32> [[TMP3]], ptr [[PTR1]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %0 = bitcast <8 x i64> %a to <16 x i32>
  %1 = bitcast <8 x i64> %b to <16 x i32>
  store <16 x i32> %0, ptr %ptr, align 16
  store <16 x i32> %1, ptr %ptr1, align 16
  ret void
}

define void @bitcast2(<4 x i64> %a, <4 x i64> %b, ptr %ptr, ptr %ptr1) {
; CHECK-LABEL: define void @bitcast2(
; CHECK-SAME: <4 x i64> [[A:%.*]], <4 x i64> [[B:%.*]], ptr [[PTR:%.*]], ptr [[PTR1:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = call <8 x i64> @llvm.vector.insert.v8i64.v4i64(<8 x i64> undef, <4 x i64> [[B]], i64 0)
; CHECK-NEXT:    [[TMP1:%.*]] = call <8 x i64> @llvm.vector.insert.v8i64.v4i64(<8 x i64> [[TMP0]], <4 x i64> [[A]], i64 4)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast <8 x i64> [[TMP1]] to <64 x i8>
; CHECK-NEXT:    [[TMP3:%.*]] = call <32 x i8> @llvm.vector.extract.v32i8.v64i8(<64 x i8> [[TMP2]], i64 0)
; CHECK-NEXT:    [[TMP4:%.*]] = call <32 x i8> @llvm.vector.extract.v32i8.v64i8(<64 x i8> [[TMP2]], i64 32)
; CHECK-NEXT:    store <32 x i8> [[TMP4]], ptr [[PTR]], align 16
; CHECK-NEXT:    store <32 x i8> [[TMP3]], ptr [[PTR1]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %0 = bitcast <4 x i64> %a to <32 x i8>
  %1 = bitcast <4 x i64> %b to <32 x i8>
  store <32 x i8> %0, ptr %ptr, align 16
  store <32 x i8> %1, ptr %ptr1, align 16
  ret void
}

define void @bitcast3(<32 x i8> %a, <32 x i8> %b, ptr %ptr, ptr %ptr1) {
; CHECK-LABEL: define void @bitcast3(
; CHECK-SAME: <32 x i8> [[A:%.*]], <32 x i8> [[B:%.*]], ptr [[PTR:%.*]], ptr [[PTR1:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = call <64 x i8> @llvm.vector.insert.v64i8.v32i8(<64 x i8> undef, <32 x i8> [[B]], i64 0)
; CHECK-NEXT:    [[TMP1:%.*]] = call <64 x i8> @llvm.vector.insert.v64i8.v32i8(<64 x i8> [[TMP0]], <32 x i8> [[A]], i64 32)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast <64 x i8> [[TMP1]] to <8 x i64>
; CHECK-NEXT:    [[TMP3:%.*]] = call <4 x i64> @llvm.vector.extract.v4i64.v8i64(<8 x i64> [[TMP2]], i64 0)
; CHECK-NEXT:    [[TMP4:%.*]] = call <4 x i64> @llvm.vector.extract.v4i64.v8i64(<8 x i64> [[TMP2]], i64 4)
; CHECK-NEXT:    store <4 x i64> [[TMP4]], ptr [[PTR]], align 16
; CHECK-NEXT:    store <4 x i64> [[TMP3]], ptr [[PTR1]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %0 = bitcast <32 x i8> %a to <4 x i64>
  %1 = bitcast <32 x i8> %b to <4 x i64>
  store <4 x i64> %0, ptr %ptr, align 16
  store <4 x i64> %1, ptr %ptr1, align 16
  ret void
}
