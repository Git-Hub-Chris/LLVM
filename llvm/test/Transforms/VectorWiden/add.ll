; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 3
; RUN: opt -passes=vector-widen -mtriple aarch64-linux-gnu -mattr=+sme2 -S %s 2>&1 | FileCheck %s

define void @add(<vscale x 4 x i32> %a, <vscale x 4 x i32> %b, <vscale x 4 x i32> %c, ptr %ptr) {
; CHECK-LABEL: define void @add(
; CHECK-SAME: <vscale x 4 x i32> [[A:%.*]], <vscale x 4 x i32> [[B:%.*]], <vscale x 4 x i32> [[C:%.*]], ptr [[PTR:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x i32> @llvm.vector.insert.nxv8i32.nxv4i32(<vscale x 8 x i32> undef, <vscale x 4 x i32> [[A]], i64 0)
; CHECK-NEXT:    [[TMP1:%.*]] = call <vscale x 8 x i32> @llvm.vector.insert.nxv8i32.nxv4i32(<vscale x 8 x i32> [[TMP0]], <vscale x 4 x i32> [[B]], i64 4)
; CHECK-NEXT:    [[TMP2:%.*]] = call <vscale x 8 x i32> @llvm.vector.insert.nxv8i32.nxv4i32(<vscale x 8 x i32> undef, <vscale x 4 x i32> [[C]], i64 0)
; CHECK-NEXT:    [[TMP3:%.*]] = call <vscale x 8 x i32> @llvm.vector.insert.nxv8i32.nxv4i32(<vscale x 8 x i32> [[TMP2]], <vscale x 4 x i32> [[C]], i64 4)
; CHECK-NEXT:    [[TMP4:%.*]] = add <vscale x 8 x i32> [[TMP1]], [[TMP3]]
; CHECK-NEXT:    [[TMP5:%.*]] = call <vscale x 4 x i32> @llvm.vector.extract.nxv4i32.nxv8i32(<vscale x 8 x i32> [[TMP4]], i64 4)
; CHECK-NEXT:    [[TMP6:%.*]] = call <vscale x 4 x i32> @llvm.vector.extract.nxv4i32.nxv8i32(<vscale x 8 x i32> [[TMP4]], i64 0)
; CHECK-NEXT:    store <vscale x 4 x i32> [[TMP6]], ptr [[PTR]], align 16
; CHECK-NEXT:    [[INCDEC_PTR3:%.*]] = getelementptr inbounds <vscale x 4 x i32>, ptr [[PTR]], i64 1
; CHECK-NEXT:    store <vscale x 4 x i32> [[TMP5]], ptr [[INCDEC_PTR3]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %add = add <vscale x 4 x i32> %a, %c
  %add4 = add <vscale x 4 x i32> %b, %c
  store <vscale x 4 x i32> %add, ptr %ptr, align 16
  %incdec.ptr3 = getelementptr inbounds <vscale x 4 x i32>, ptr %ptr, i64 1
  store <vscale x 4 x i32> %add4, ptr %incdec.ptr3, align 16
  ret void
}

define void @add_ir_flags(<vscale x 4 x i32> %a, <vscale x 4 x i32> %b, <vscale x 4 x i32> %c, ptr %ptr) {
; CHECK-LABEL: define void @add_ir_flags(
; CHECK-SAME: <vscale x 4 x i32> [[A:%.*]], <vscale x 4 x i32> [[B:%.*]], <vscale x 4 x i32> [[C:%.*]], ptr [[PTR:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x i32> @llvm.vector.insert.nxv8i32.nxv4i32(<vscale x 8 x i32> undef, <vscale x 4 x i32> [[A]], i64 0)
; CHECK-NEXT:    [[TMP1:%.*]] = call <vscale x 8 x i32> @llvm.vector.insert.nxv8i32.nxv4i32(<vscale x 8 x i32> [[TMP0]], <vscale x 4 x i32> [[B]], i64 4)
; CHECK-NEXT:    [[TMP2:%.*]] = call <vscale x 8 x i32> @llvm.vector.insert.nxv8i32.nxv4i32(<vscale x 8 x i32> undef, <vscale x 4 x i32> [[C]], i64 0)
; CHECK-NEXT:    [[TMP3:%.*]] = call <vscale x 8 x i32> @llvm.vector.insert.nxv8i32.nxv4i32(<vscale x 8 x i32> [[TMP2]], <vscale x 4 x i32> [[C]], i64 4)
; CHECK-NEXT:    [[TMP4:%.*]] = add nuw <vscale x 8 x i32> [[TMP1]], [[TMP3]]
; CHECK-NEXT:    [[TMP5:%.*]] = call <vscale x 4 x i32> @llvm.vector.extract.nxv4i32.nxv8i32(<vscale x 8 x i32> [[TMP4]], i64 4)
; CHECK-NEXT:    [[TMP6:%.*]] = call <vscale x 4 x i32> @llvm.vector.extract.nxv4i32.nxv8i32(<vscale x 8 x i32> [[TMP4]], i64 0)
; CHECK-NEXT:    store <vscale x 4 x i32> [[TMP6]], ptr [[PTR]], align 16
; CHECK-NEXT:    [[INCDEC_PTR3:%.*]] = getelementptr inbounds <vscale x 4 x i32>, ptr [[PTR]], i64 1
; CHECK-NEXT:    store <vscale x 4 x i32> [[TMP5]], ptr [[INCDEC_PTR3]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %add = add nuw nsw <vscale x 4 x i32> %a, %c
  %add4 = add nuw <vscale x 4 x i32> %b, %c
  store <vscale x 4 x i32> %add, ptr %ptr, align 16
  %incdec.ptr3 = getelementptr inbounds <vscale x 4 x i32>, ptr %ptr, i64 1
  store <vscale x 4 x i32> %add4, ptr %incdec.ptr3, align 16
  ret void
}
