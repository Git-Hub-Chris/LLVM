; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt < %s -mtriple=x86_64 -mattr=+cf -passes='simplifycfg<hoist-loads-stores-with-cond-faulting>' -simplifycfg-require-and-preserve-domtree=1 -S | FileCheck %s

;; Basic case: check masked.load/store is generated for i16/i32/i64.
define void @basic(i1 %cond, ptr %b, ptr %p, ptr %q) {
; CHECK-LABEL: @basic(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i1 [[COND:%.*]] to <1 x i1>
; CHECK-NEXT:    [[TMP1:%.*]] = call <1 x i16> @llvm.masked.load.v1i16.p0(ptr [[P:%.*]], i32 2, <1 x i1> [[TMP0]], <1 x i16> poison)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast <1 x i16> [[TMP1]] to i16
; CHECK-NEXT:    [[TMP3:%.*]] = call <1 x i32> @llvm.masked.load.v1i32.p0(ptr [[Q:%.*]], i32 4, <1 x i1> [[TMP0]], <1 x i32> poison)
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <1 x i32> [[TMP3]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = call <1 x i64> @llvm.masked.load.v1i64.p0(ptr [[B:%.*]], i32 8, <1 x i1> [[TMP0]], <1 x i64> poison)
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <1 x i64> [[TMP5]] to i64
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i16 [[TMP2]] to <1 x i16>
; CHECK-NEXT:    call void @llvm.masked.store.v1i16.p0(<1 x i16> [[TMP7]], ptr [[B]], i32 2, <1 x i1> [[TMP0]])
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i32 [[TMP4]] to <1 x i32>
; CHECK-NEXT:    call void @llvm.masked.store.v1i32.p0(<1 x i32> [[TMP8]], ptr [[P]], i32 4, <1 x i1> [[TMP0]])
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i64 [[TMP6]] to <1 x i64>
; CHECK-NEXT:    call void @llvm.masked.store.v1i64.p0(<1 x i64> [[TMP9]], ptr [[Q]], i32 8, <1 x i1> [[TMP0]])
; CHECK-NEXT:    ret void
;
entry:
  br i1 %cond, label %if.true, label %if.false

if.false:
  br label %if.end

if.true:
  %0 = load i16, ptr %p, align 2
  %1 = load i32, ptr %q, align 4
  %2 = load i64, ptr %b, align 8
  store i16 %0, ptr %b, align 2
  store i32 %1, ptr %p, align 4
  store i64 %2, ptr %q, align 8
  br label %if.false

if.end:
  ret void
}

;; Successor 1 branches to successor 0.
define void @succ1to0(ptr %p, ptr %q, i32 %a) {
; CHECK-LABEL: @succ1to0(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[A:%.*]], 0
; CHECK-NEXT:    [[TMP0:%.*]] = xor i1 [[TOBOOL]], true
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i1 [[TMP0]] to <1 x i1>
; CHECK-NEXT:    [[TMP2:%.*]] = call <1 x i32> @llvm.masked.load.v1i32.p0(ptr [[Q:%.*]], i32 4, <1 x i1> [[TMP1]], <1 x i32> poison)
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast <1 x i32> [[TMP2]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i32 [[TMP3]] to <1 x i32>
; CHECK-NEXT:    call void @llvm.masked.store.v1i32.p0(<1 x i32> [[TMP4]], ptr [[P:%.*]], i32 4, <1 x i1> [[TMP1]])
; CHECK-NEXT:    ret void
;
entry:
  %tobool = icmp ne i32 %a, 0
  br i1 %tobool, label %if.end, label %if.then

if.end:
  ret void

if.then:
  %0 = load i32, ptr %q
  store i32 %0, ptr %p
  br label %if.end
}

;; Successor 1 branches to successor 0 and there is a phi node.
define i32 @succ1to0_phi(ptr %p)  {
; CHECK-LABEL: @succ1to0_phi(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq ptr [[P:%.*]], null
; CHECK-NEXT:    [[TMP0:%.*]] = xor i1 [[COND]], true
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i1 [[TMP0]] to <1 x i1>
; CHECK-NEXT:    [[TMP2:%.*]] = call <1 x i32> @llvm.masked.load.v1i32.p0(ptr [[P]], i32 4, <1 x i1> [[TMP1]], <1 x i32> poison)
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast <1 x i32> [[TMP2]] to i32
; CHECK-NEXT:    [[SPEC_SELECT:%.*]] = select i1 [[COND]], i32 0, i32 [[TMP3]]
; CHECK-NEXT:    ret i32 [[SPEC_SELECT]]
;
entry:
  %cond = icmp eq ptr %p, null
  br i1 %cond, label %if.true, label %if.false

if.false:
  %0 = load i32, ptr %p
  br label %if.true

if.true:
  %res = phi i32 [ %0, %if.false ], [ 0, %entry ]
  ret i32 %res
}

;; Successor 0 branches to successor 1.
define void @succ0to1(i32 %a, ptr %b, ptr %p, ptr %q) {
; CHECK-LABEL: @succ0to1(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i32 [[A:%.*]], 0
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i1 [[COND]] to <1 x i1>
; CHECK-NEXT:    [[TMP1:%.*]] = call <1 x i32> @llvm.masked.load.v1i32.p0(ptr [[B:%.*]], i32 4, <1 x i1> [[TMP0]], <1 x i32> poison)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast <1 x i32> [[TMP1]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast i32 [[TMP2]] to <1 x i32>
; CHECK-NEXT:    call void @llvm.masked.store.v1i32.p0(<1 x i32> [[TMP3]], ptr [[P:%.*]], i32 4, <1 x i1> [[TMP0]])
; CHECK-NEXT:    store i32 1, ptr [[Q:%.*]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %cond = icmp eq i32 %a, 0
  br i1 %cond, label %if.true, label %if.false

if.false:
  store i32 1, ptr %q
  br label %if.end

if.true:
  %0 = load i32, ptr %b
  store i32 %0, ptr %p
  br label %if.false

if.end:
  ret void
}

;; Load after store can be hoisted.
define i64 @load_after_store(i32 %a, ptr %b, ptr %p) {
; CHECK-LABEL: @load_after_store(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i32 [[A:%.*]], 0
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i1 [[COND]] to <1 x i1>
; CHECK-NEXT:    call void @llvm.masked.store.v1i32.p0(<1 x i32> <i32 1>, ptr [[B:%.*]], i32 4, <1 x i1> [[TMP0]])
; CHECK-NEXT:    [[TMP1:%.*]] = call <1 x i16> @llvm.masked.load.v1i16.p0(ptr [[P:%.*]], i32 2, <1 x i1> [[TMP0]], <1 x i16> poison)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast <1 x i16> [[TMP1]] to i16
; CHECK-NEXT:    [[ZEXT:%.*]] = zext i16 [[TMP2]] to i64
; CHECK-NEXT:    [[SPEC_SELECT:%.*]] = select i1 [[COND]], i64 [[ZEXT]], i64 0
; CHECK-NEXT:    ret i64 [[SPEC_SELECT]]
;
entry:
  %cond = icmp eq i32 %a, 0
  br i1 %cond, label %if.true, label %if.end

if.true:
  store i32 1, ptr %b
  %0 = load i16, ptr %p
  %zext = zext i16 %0 to i64
  ret i64 %zext

if.end:
  ret i64 0
}

;; Speculatable memory read doesn't prevent the hoist.
define void @load_skip_speculatable_memory_read(i32 %a, ptr %p, ptr %q) {
; CHECK-LABEL: @load_skip_speculatable_memory_read(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i32 [[A:%.*]], 0
; CHECK-NEXT:    [[READ:%.*]] = call i32 @read_memory_only()
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i1 [[COND]] to <1 x i1>
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i32 [[READ]] to <1 x i32>
; CHECK-NEXT:    call void @llvm.masked.store.v1i32.p0(<1 x i32> [[TMP1]], ptr [[P:%.*]], i32 4, <1 x i1> [[TMP0]])
; CHECK-NEXT:    store i32 1, ptr [[Q:%.*]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %cond = icmp eq i32 %a, 0
  br i1 %cond, label %if.true, label %if.false

if.false:
  store i32 1, ptr %q
  br label %if.end

if.true:
  %read = call i32 @read_memory_only()
  store i32 %read, ptr %p
  br label %if.false

if.end:
  ret void
}

;; Source of the load can be a GEP.
define i32 @load_from_gep(ptr %p)  {
; CHECK-LABEL: @load_from_gep(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq ptr [[P:%.*]], null
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i8, ptr [[P]], i64 16
; CHECK-NEXT:    [[TMP0:%.*]] = xor i1 [[COND]], true
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i1 [[TMP0]] to <1 x i1>
; CHECK-NEXT:    [[TMP2:%.*]] = call <1 x i32> @llvm.masked.load.v1i32.p0(ptr [[ARRAYIDX]], i32 4, <1 x i1> [[TMP1]], <1 x i32> poison)
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast <1 x i32> [[TMP2]] to i32
; CHECK-NEXT:    [[SPEC_SELECT:%.*]] = select i1 [[COND]], i32 0, i32 [[TMP3]]
; CHECK-NEXT:    ret i32 [[SPEC_SELECT]]
;
entry:
  %cond = icmp eq ptr %p, null
  br i1 %cond, label %if.true, label %if.false

if.false:
  %arrayidx = getelementptr inbounds i8, ptr %p, i64 16
  %0 = load i32, ptr %arrayidx
  br label %if.true

if.true:
  %res = phi i32 [ %0, %if.false ], [ 0, %entry ]
  ret i32 %res
}

;; Both of successor 0 and successor 1 have a single predecessor.
;; TODO: Support transform for this case.
define void @single_predecessor(ptr %p, ptr %q, i32 %a) {
; CHECK-LABEL: @single_predecessor(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[TOBOOL]], label [[IF_END:%.*]], label [[IF_THEN:%.*]]
; CHECK:       common.ret:
; CHECK-NEXT:    ret void
; CHECK:       if.end:
; CHECK-NEXT:    store i32 1, ptr [[Q:%.*]], align 4
; CHECK-NEXT:    br label [[COMMON_RET:%.*]]
; CHECK:       if.then:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[Q]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[P:%.*]], align 4
; CHECK-NEXT:    br label [[COMMON_RET]]
;
entry:
  %tobool = icmp ne i32 %a, 0
  br i1 %tobool, label %if.end, label %if.then

if.end:
  store i32 1, ptr %q
  ret void

if.then:
  %0 = load i32, ptr %q
  store i32 %0, ptr %p
  ret void
}

;; Not do hoist if the cost of instructions to be hoisted is expensive.
define i32 @not_cheap_to_hoist(i32 %a, ptr %b, ptr %p, ptr %q, i32 %v0, i32 %v1, i32 %v2, i1 %cc) {
; CHECK-LABEL: @not_cheap_to_hoist(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i32 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[COND]], label [[IF_TRUE:%.*]], label [[IF_FALSE:%.*]]
; CHECK:       common.ret:
; CHECK-NEXT:    [[COMMON_RET_OP:%.*]] = phi i32 [ [[VVVV:%.*]], [[IF_FALSE]] ], [ 0, [[IF_TRUE]] ]
; CHECK-NEXT:    ret i32 [[COMMON_RET_OP]]
; CHECK:       if.false:
; CHECK-NEXT:    store i64 1, ptr [[P:%.*]], align 8
; CHECK-NEXT:    store i16 2, ptr [[Q:%.*]], align 2
; CHECK-NEXT:    [[V:%.*]] = udiv i32 [[A]], 12345
; CHECK-NEXT:    [[VV:%.*]] = mul i32 [[V]], [[V0:%.*]]
; CHECK-NEXT:    [[VVV:%.*]] = mul i32 [[VV]], [[V1:%.*]]
; CHECK-NEXT:    [[VVVV]] = select i1 [[CC:%.*]], i32 [[V2:%.*]], i32 [[VVV]]
; CHECK-NEXT:    br label [[COMMON_RET:%.*]]
; CHECK:       if.true:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B:%.*]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[P]], align 4
; CHECK-NEXT:    br label [[COMMON_RET]]
;
entry:
  %cond = icmp eq i32 %a, 0
  br i1 %cond, label %if.true, label %if.false

if.false:
  store i64 1, ptr %p
  store i16 2, ptr %q

  %v = udiv i32 %a, 12345
  %vv = mul i32 %v, %v0
  %vvv = mul i32 %vv, %v1
  %vvvv = select i1 %cc, i32 %v2, i32 %vvv
  ret i32 %vvvv

if.true:
  %0 = load i32, ptr %b
  store i32 %0, ptr %p
  br label %if.end

if.end:
  ret i32 0
}

;; Not hoist if there is more than 1 prodecessor.
define void @not_single_predecessor(ptr %p, ptr %q, i32 %a) {
; CHECK-LABEL: @not_single_predecessor(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[TOBOOL]], label [[IF_END:%.*]], label [[IF_THEN:%.*]]
; CHECK:       if.end:
; CHECK-NEXT:    br label [[IF_THEN]]
; CHECK:       if.then:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[Q:%.*]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[P:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END]]
;
entry:
  %tobool = icmp ne i32 %a, 0
  br i1 %tobool, label %if.end, label %if.then

if.end:
  br label %if.then

if.then:
  %1 = load i32, ptr %q
  store i32 %1, ptr %p
  br label %if.end
}

;; Not hoist b/c i8 is not supported by conditional faulting
define void @not_supported_type(i8 %a, ptr %b, ptr %p, ptr %q) {
; CHECK-LABEL: @not_supported_type(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i8 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[COND]], label [[IF_TRUE:%.*]], label [[IF_FALSE:%.*]]
; CHECK:       if.false:
; CHECK-NEXT:    store i8 1, ptr [[Q:%.*]], align 1
; CHECK-NEXT:    br label [[IF_END:%.*]]
; CHECK:       if.true:
; CHECK-NEXT:    [[TMP0:%.*]] = load i8, ptr [[B:%.*]], align 1
; CHECK-NEXT:    store i8 [[TMP0]], ptr [[P:%.*]], align 1
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cond = icmp eq i8 %a, 0
  br i1 %cond, label %if.true, label %if.false

if.false:
  store i8 1, ptr %q
  br label %if.end

if.true:
  %0 = load i8, ptr %b
  store i8 %0, ptr %p
  br label %if.end

if.end:
  ret void
}

;; Not hoist if the terminator is not br.
define void @not_br_terminator(i32 %a, ptr %b, ptr %p, ptr %q) {
; CHECK-LABEL: @not_br_terminator(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    switch i32 [[A:%.*]], label [[IF_END:%.*]] [
; CHECK-NEXT:      i32 1, label [[IF_FALSE:%.*]]
; CHECK-NEXT:      i32 2, label [[IF_TRUE:%.*]]
; CHECK-NEXT:    ]
; CHECK:       if.false:
; CHECK-NEXT:    store i32 1, ptr [[Q:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.true:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B:%.*]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[P:%.*]], align 4
; CHECK-NEXT:    br label [[IF_FALSE]]
; CHECK:       if.end:
; CHECK-NEXT:    ret void
;
entry:
  switch i32 %a, label %if.end [
  i32 1, label %if.false
  i32 2, label %if.true
  ]

if.false:
  store i32 1, ptr %q, align 4
  br label %if.end

if.true:
  %0 = load i32, ptr %b, align 4
  store i32 %0, ptr %p, align 4
  br label %if.false

if.end:
  ret void
}

;; Not hoist if the instruction to be hoist is atomic/volatile.
define void @not_simple(i32 %a, ptr %b, ptr %p, ptr %q) {
; CHECK-LABEL: @not_simple(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i32 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[COND]], label [[IF_TRUE:%.*]], label [[IF_FALSE:%.*]]
; CHECK:       if.false:
; CHECK-NEXT:    store atomic i32 1, ptr [[Q:%.*]] seq_cst, align 4
; CHECK-NEXT:    br label [[IF_END:%.*]]
; CHECK:       if.true:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B:%.*]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[P:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cond = icmp eq i32 %a, 0
  br i1 %cond, label %if.true, label %if.false

if.false:
  store atomic i32 1, ptr %q seq_cst, align 4
  br label %if.end

if.true:
  %0 = load i32, ptr %b, align 4
  store i32 %0, ptr %p, align 4
  br label %if.end

if.end:
  ret void
}

;; Not hoist if there is a load/store that can not be hoisted in the same bb.
define void @not_hoistable_store(i32 %a, ptr %b, ptr %p, ptr %q) {
; CHECK-LABEL: @not_hoistable_store(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i32 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[COND]], label [[IF_TRUE:%.*]], label [[IF_FALSE:%.*]]
; CHECK:       if.false:
; CHECK-NEXT:    store i32 1, ptr [[Q:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END:%.*]]
; CHECK:       if.true:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B:%.*]], align 4
; CHECK-NEXT:    store volatile i32 [[TMP0]], ptr [[P:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cond = icmp eq i32 %a, 0
  br i1 %cond, label %if.true, label %if.false

if.false:
  store i32 1, ptr %q, align 4
  br label %if.end

if.true:
  %0 = load i32, ptr %b, align 4
  store volatile i32 %0, ptr %p, align 4
  br label %if.end

if.end:
  ret void
}

;; Not hoist if there is an instruction that has side effect in the same bb.
define void @not_hoistable_sideeffect(i32 %a, ptr %b, ptr %p, ptr %q) {
; CHECK-LABEL: @not_hoistable_sideeffect(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i32 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[COND]], label [[IF_TRUE:%.*]], label [[IF_FALSE:%.*]]
; CHECK:       if.false:
; CHECK-NEXT:    store i32 1, ptr [[Q:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END:%.*]]
; CHECK:       if.true:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B:%.*]], align 4
; CHECK-NEXT:    [[RMW:%.*]] = atomicrmw xchg ptr [[Q]], double 4.000000e+00 seq_cst, align 8
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[P:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cond = icmp eq i32 %a, 0
  br i1 %cond, label %if.true, label %if.false

if.false:
  store i32 1, ptr %q, align 4
  br label %if.end

if.true:
  %0 = load i32, ptr %b, align 4
  %rmw= atomicrmw xchg ptr %q, double 4.0 seq_cst
  store i32 %0, ptr %p, align 4
  br label %if.end

if.end:
  ret void
}

;; Not hoist b/c the operand of store does not dominate the branch.
;; TODO: Could we improve it?
define void @not_ops_dominate_br(i32 %a, ptr %b, ptr %p, ptr %q) {
; CHECK-LABEL: @not_ops_dominate_br(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i32 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[COND]], label [[IF_TRUE:%.*]], label [[IF_FALSE:%.*]]
; CHECK:       if.false:
; CHECK-NEXT:    [[ADD:%.*]] = add i32 [[A]], 2
; CHECK-NEXT:    store i32 [[ADD]], ptr [[Q:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END:%.*]]
; CHECK:       if.true:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B:%.*]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[P:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cond = icmp eq i32 %a, 0
  br i1 %cond, label %if.true, label %if.false

if.false:
  %add = add i32 %a, 2
  store i32 %add, ptr %q, align 4
  br label %if.end

if.true:
  %1 = load i32, ptr %b, align 4
  store i32 %1, ptr %p, align 4
  br label %if.end

if.end:
  ret void
}

;; Not hoist if the branch is predictable and the `then` BB is not likely to execute.
define void @not_likely_to_execute(ptr %p, ptr %q, i32 %a) {
; CHECK-LABEL: @not_likely_to_execute(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[A:%.*]], 0
; CHECK-NEXT:    br i1 [[TOBOOL]], label [[IF_THEN:%.*]], label [[IF_END:%.*]], !prof [[PROF0:![0-9]+]]
; CHECK:       if.end:
; CHECK-NEXT:    ret void
; CHECK:       if.then:
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[Q:%.*]], align 4
; CHECK-NEXT:    store i32 [[TMP0]], ptr [[P:%.*]], align 4
; CHECK-NEXT:    br label [[IF_END]]
;
entry:
  %tobool = icmp ne i32 %a, 0
  br i1 %tobool, label %if.then, label %if.end, !prof !0

if.end:
  ret void

if.then:
  %0 = load i32, ptr %q
  store i32 %0, ptr %p
  br label %if.end
}

;; Now the optimization hoist-loads-stores-with-cond-faulting is run in codegen,
;; which is after sroa and alloca is optimized away. So we don't need to do the transform
;; for this case. But in the future, it is probably moved before sroa.
define void @not_alloca(ptr %p, ptr %q, i32 %a) {
; CHECK-LABEL: @not_alloca(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[P_ADDR:%.*]] = alloca ptr, align 8
; CHECK-NEXT:    [[Q_ADDR:%.*]] = alloca ptr, align 8
; CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store ptr [[P:%.*]], ptr [[P_ADDR]], align 8
; CHECK-NEXT:    store ptr [[Q:%.*]], ptr [[Q_ADDR]], align 8
; CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
; CHECK-NEXT:    [[TOBOOL:%.*]] = icmp ne i32 [[TMP0]], 0
; CHECK-NEXT:    br i1 [[TOBOOL]], label [[IF_THEN:%.*]], label [[IF_END:%.*]]
; CHECK:       if.then:
; CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[Q_ADDR]], align 8
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[P_ADDR]], align 8
; CHECK-NEXT:    store i32 [[TMP2]], ptr [[TMP3]], align 4
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.end:
; CHECK-NEXT:    ret void
;
entry:
  %p.addr = alloca ptr
  %q.addr = alloca ptr
  %a.addr = alloca i32
  store ptr %p, ptr %p.addr
  store ptr %q, ptr %q.addr
  store i32 %a, ptr %a.addr
  %0 = load i32, ptr %a.addr
  %tobool = icmp ne i32 %0, 0
  br i1 %tobool, label %if.then, label %if.end

if.then:
  %1 = load ptr, ptr %q.addr
  %2 = load i32, ptr %1
  %3 = load ptr, ptr %p.addr
  store i32 %2, ptr %3
  br label %if.end

if.end:
  ret void
}

declare i32 @read_memory_only() readonly nounwind willreturn speculatable

!0 = !{!"branch_weights", i32 1, i32 99}
