; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -S < %s -passes=dce  | FileCheck %s


; BPF

declare i64 @llvm.bpf.load.half(ptr, i64)
declare i64 @llvm.bpf.load.word(ptr, i64)
declare i64 @llvm.bpf.load.byte(ptr, i64)

define void @test_bpf_load_half(ptr %a, i64 %b) {
; CHECK-LABEL: define void @test_bpf_load_half(
; CHECK-SAME: ptr [[A:%.*]], i64 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call i64 @llvm.bpf.load.half(ptr %a, i64 %b)
  ret void
}

define void @test_bpf_load_word(ptr %a, i64 %b) {
; CHECK-LABEL: define void @test_bpf_load_word(
; CHECK-SAME: ptr [[A:%.*]], i64 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call i64 @llvm.bpf.load.word(ptr %a, i64 %b)
  ret void
}

define void @test_bpf_load_byte(ptr %a, i64 %b) {
; CHECK-LABEL: define void @test_bpf_load_byte(
; CHECK-SAME: ptr [[A:%.*]], i64 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call i64 @llvm.bpf.load.byte(ptr %a, i64 %b)
  ret void
}

; LoongArch

declare <16 x i8> @llvm.loongarch.lsx.vld(ptr, i32)
declare <16 x i8> @llvm.loongarch.lsx.vldx(ptr, i64)
declare <16 x i8> @llvm.loongarch.lsx.vldrepl.b(ptr, i32)
declare <8 x i16> @llvm.loongarch.lsx.vldrepl.h(ptr, i32)
declare <4 x i32> @llvm.loongarch.lsx.vldrepl.w(ptr, i32)
declare <2 x i64> @llvm.loongarch.lsx.vldrepl.d(ptr, i32)

declare <32 x i8> @llvm.loongarch.lasx.xvld(ptr, i32)
declare <32 x i8> @llvm.loongarch.lasx.xvldx(ptr, i64)
declare <32 x i8> @llvm.loongarch.lasx.xvldrepl.b(ptr, i32)
declare <16 x i16> @llvm.loongarch.lasx.xvldrepl.h(ptr, i32)
declare <8 x i32> @llvm.loongarch.lasx.xvldrepl.w(ptr, i32)
declare <4 x i64> @llvm.loongarch.lasx.xvldrepl.d(ptr, i32)

define void @test_loongarch_lsx_vld(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lsx_vld(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <16 x i8> @llvm.loongarch.lsx.vld(ptr %a, i32 8)
  ret void
}

define void @test_loongarch_lsx_vldx(ptr %a, i64 %b) {
; CHECK-LABEL: define void @test_loongarch_lsx_vldx(
; CHECK-SAME: ptr [[A:%.*]], i64 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <16 x i8> @llvm.loongarch.lsx.vldx(ptr %a, i64 %b)
  ret void
}

define void @test_loongarch_lsx_vldrepl_b(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lsx_vldrepl_b(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <16 x i8> @llvm.loongarch.lsx.vldrepl.b(ptr %a, i32 12)
  ret void
}

define void @test_loongarch_lsx_vldrepl_h(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lsx_vldrepl_h(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <8 x i16> @llvm.loongarch.lsx.vldrepl.h(ptr %a, i32 12)
  ret void
}

define void @test_loongarch_lsx_vldrepl_w(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lsx_vldrepl_w(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <4 x i32> @llvm.loongarch.lsx.vldrepl.w(ptr %a, i32 4)
  ret void
}

define void @test_loongarch_lsx_vldrepl_d(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lsx_vldrepl_d(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <2 x i64> @llvm.loongarch.lsx.vldrepl.d(ptr %a, i32 4)
  ret void
}

define void @test_loongarch_lasx_xvld(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lasx_xvld(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <32 x i8> @llvm.loongarch.lasx.xvld(ptr %a, i32 4)
  ret void
}

define void @test_loongarch_lasx_xvldx(ptr %a, i64 %b) {
; CHECK-LABEL: define void @test_loongarch_lasx_xvldx(
; CHECK-SAME: ptr [[A:%.*]], i64 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <32 x i8> @llvm.loongarch.lasx.xvldx(ptr %a, i64 %b)
  ret void
}

define void @test_loongarch_lasx_xvldrepl_b(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lasx_xvldrepl_b(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <32 x i8> @llvm.loongarch.lasx.xvldrepl.b(ptr %a, i32 4)
  ret void
}

define void @test_loongarch_lasx_xvldrepl_h(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lasx_xvldrepl_h(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <16 x i16> @llvm.loongarch.lasx.xvldrepl.h(ptr %a, i32 4)
  ret void
}

define void @test_loongarch_lasx_xvldrepl_w(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lasx_xvldrepl_w(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <8 x i32> @llvm.loongarch.lasx.xvldrepl.w(ptr %a, i32 4)
  ret void
}

define void @test_loongarch_lasx_xvldrepl_d(ptr %a) {
; CHECK-LABEL: define void @test_loongarch_lasx_xvldrepl_d(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <4 x i64> @llvm.loongarch.lasx.xvldrepl.d(ptr %a, i32 4)
  ret void
}

; MIPS

declare i32 @llvm.mips.rddsp(i32)
declare <4 x i8> @llvm.mips.pick.qb(<4 x i8>, <4 x i8>)
declare <2 x i16> @llvm.mips.pick.ph(<2 x i16>, <2 x i16>)
declare i32 @llvm.mips.bposge32()
declare i32 @llvm.mips.lbux(ptr, i32)
declare i32 @llvm.mips.lhx(ptr, i32)
declare i32 @llvm.mips.lwx(ptr, i32)
declare <16 x i8> @llvm.mips.ld.b(ptr, i32)
declare <8 x i16> @llvm.mips.ld.h(ptr, i32)
declare <4 x i32> @llvm.mips.ld.w(ptr, i32)
declare <2 x i64> @llvm.mips.ld.d(ptr, i32)
declare <2 x i64> @llvm.mips.ldr.d(ptr, i32)
declare <4 x i32> @llvm.mips.ldr.w(ptr, i32)

define void @test_mips_rddsp() {
; CHECK-LABEL: define void @test_mips_rddsp() {
; CHECK-NEXT:    ret void
;
  %v = call i32 @llvm.mips.rddsp(i32 4)
  ret void
}

define void @test_llvm_mips_pick_qb(<4 x i8> %a, <4 x i8> %b) {
; CHECK-LABEL: define void @test_llvm_mips_pick_qb(
; CHECK-SAME: <4 x i8> [[A:%.*]], <4 x i8> [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <4 x i8> @llvm.mips.pick.qb(<4 x i8> %a, <4 x i8> %b)
  ret void
}

define void @test_llvm_mips_pick_ph(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: define void @test_llvm_mips_pick_ph(
; CHECK-SAME: <2 x i16> [[A:%.*]], <2 x i16> [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <2 x i16> @llvm.mips.pick.ph(<2 x i16> %a, <2 x i16> %b)
  ret void
}

define void @test_llvm_mips_bposge32() {
; CHECK-LABEL: define void @test_llvm_mips_bposge32() {
; CHECK-NEXT:    ret void
;
  %v = call i32 @llvm.mips.bposge32()
  ret void
}

define void @test_llvm_mips_lbux(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_lbux(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call i32 @llvm.mips.lbux(ptr %a, i32 %b)
  ret void
}

define void @test_llvm_mips_lhx(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_lhx(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call i32 @llvm.mips.lhx(ptr %a, i32 %b)
  ret void
}

define void @test_llvm_mips_lwx(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_lwx(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call i32 @llvm.mips.lwx(ptr %a, i32 %b)
  ret void
}

define void @test_llvm_mips_ld_b(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_ld_b(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <16 x i8> @llvm.mips.ld.b(ptr %a, i32 %b)
  ret void
}

define void @test_llvm_mips_ld_h(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_ld_h(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <8 x i16> @llvm.mips.ld.h(ptr %a, i32 %b)
  ret void
}

define void @test_llvm_mips_ld_w(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_ld_w(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <4 x i32> @llvm.mips.ld.w(ptr %a, i32 %b)
  ret void
}

define void @test_llvm_mips_ld_d(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_ld_d(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <2 x i64> @llvm.mips.ld.d(ptr %a, i32 %b)
  ret void
}

define void @test_llvm_mips_ldr_d(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_ldr_d(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <2 x i64> @llvm.mips.ldr.d(ptr %a, i32 %b)
  ret void
}

define void @test_llvm_mips_ldr_w(ptr %a, i32 %b) {
; CHECK-LABEL: define void @test_llvm_mips_ldr_w(
; CHECK-SAME: ptr [[A:%.*]], i32 [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <4 x i32> @llvm.mips.ldr.w(ptr %a, i32 %b)
  ret void
}

; NVVM

declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.f16.p0i8(i8 addrspace(0)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_f16_p0i8(i8 addrspace(0)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.f16.p0i8(i8 addrspace(0)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_stride_f16_p0i8(i8 addrspace(0)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_stride_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.f16.p3i8(i8 addrspace(3)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_f16_p3i8(i8 addrspace(3)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.f16.p3i8(i8 addrspace(3)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_stride_f16_p3i8(i8 addrspace(3)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_stride_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.f16.p1i8(i8 addrspace(1)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_f16_p1i8(i8 addrspace(1)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.f16.p1i8(i8 addrspace(1)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_stride_f16_p1i8(i8 addrspace(1)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_row_stride_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.row.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.f16.p0i8(i8 addrspace(0)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_f16_p0i8(i8 addrspace(0)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.f16.p0i8(i8 addrspace(0)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_stride_f16_p0i8(i8 addrspace(0)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_stride_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.f16.p3i8(i8 addrspace(3)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_f16_p3i8(i8 addrspace(3)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.f16.p3i8(i8 addrspace(3)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_stride_f16_p3i8(i8 addrspace(3)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_stride_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.f16.p1i8(i8 addrspace(1)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_f16_p1i8(i8 addrspace(1)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.f16.p1i8(i8 addrspace(1)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_stride_f16_p1i8(i8 addrspace(1)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_a_col_stride_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.a.col.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.f16.p0i8(i8 addrspace(0)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_f16_p0i8(i8 addrspace(0)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.f16.p0i8(i8 addrspace(0)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_stride_f16_p0i8(i8 addrspace(0)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_stride_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.f16.p3i8(i8 addrspace(3)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_f16_p3i8(i8 addrspace(3)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.f16.p3i8(i8 addrspace(3)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_stride_f16_p3i8(i8 addrspace(3)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_stride_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.f16.p1i8(i8 addrspace(1)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_f16_p1i8(i8 addrspace(1)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.f16.p1i8(i8 addrspace(1)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_stride_f16_p1i8(i8 addrspace(1)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_row_stride_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.row.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.f16.p0i8(i8 addrspace(0)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_f16_p0i8(i8 addrspace(0)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.f16.p0i8(i8 addrspace(0)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_stride_f16_p0i8(i8 addrspace(0)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_stride_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.f16.p3i8(i8 addrspace(3)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_f16_p3i8(i8 addrspace(3)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.f16.p3i8(i8 addrspace(3)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_stride_f16_p3i8(i8 addrspace(3)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_stride_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.f16.p1i8(i8 addrspace(1)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_f16_p1i8(i8 addrspace(1)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.f16.p1i8(i8 addrspace(1)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_stride_f16_p1i8(i8 addrspace(1)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_b_col_stride_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.b.col.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.f16.p0i8(i8 addrspace(0)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f16_p0i8(i8 addrspace(0)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.f16.p0i8(i8 addrspace(0)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f16_p0i8(i8 addrspace(0)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.f16.p3i8(i8 addrspace(3)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f16_p3i8(i8 addrspace(3)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.f16.p3i8(i8 addrspace(3)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f16_p3i8(i8 addrspace(3)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.f16.p1i8(i8 addrspace(1)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f16_p1i8(i8 addrspace(1)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.f16.p1i8(i8 addrspace(1)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f16_p1i8(i8 addrspace(1)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.f16.p0i8(i8 addrspace(0)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f16_p0i8(i8 addrspace(0)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.f16.p0i8(i8 addrspace(0)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f16_p0i8(i8 addrspace(0)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f16_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f16.p0i8(i8 addrspace(0)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.f16.p3i8(i8 addrspace(3)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f16_p3i8(i8 addrspace(3)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.f16.p3i8(i8 addrspace(3)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f16_p3i8(i8 addrspace(3)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f16_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f16.p3i8(i8 addrspace(3)* %src , i32 %stride);
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.f16.p1i8(i8 addrspace(1)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f16_p1i8(i8 addrspace(1)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.f16.p1i8(i8 addrspace(1)* %src );
  ret void;
}


declare {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f16_p1i8(i8 addrspace(1)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f16_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {<2 x half>, <2 x half>, <2 x half>, <2 x half>} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f16.p1i8(i8 addrspace(1)* %src , i32 %stride);
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.f32.p0i8(i8 addrspace(0)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f32_p0i8(i8 addrspace(0)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f32_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.f32.p0i8(i8 addrspace(0)* %src );
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f32.p0i8(i8 addrspace(0)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f32_p0i8(i8 addrspace(0)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f32_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f32.p0i8(i8 addrspace(0)* %src , i32 %stride);
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.f32.p3i8(i8 addrspace(3)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f32_p3i8(i8 addrspace(3)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f32_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.f32.p3i8(i8 addrspace(3)* %src );
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f32.p3i8(i8 addrspace(3)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f32_p3i8(i8 addrspace(3)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f32_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f32.p3i8(i8 addrspace(3)* %src , i32 %stride);
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.f32.p1i8(i8 addrspace(1)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f32_p1i8(i8 addrspace(1)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_f32_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.f32.p1i8(i8 addrspace(1)* %src );
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f32.p1i8(i8 addrspace(1)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f32_p1i8(i8 addrspace(1)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_row_stride_f32_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f32.p1i8(i8 addrspace(1)* %src , i32 %stride);
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.f32.p0i8(i8 addrspace(0)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f32_p0i8(i8 addrspace(0)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f32_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.f32.p0i8(i8 addrspace(0)* %src );
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f32.p0i8(i8 addrspace(0)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f32_p0i8(i8 addrspace(0)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f32_p0i8(
; CHECK-SAME: ptr [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f32.p0i8(i8 addrspace(0)* %src , i32 %stride);
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.f32.p3i8(i8 addrspace(3)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f32_p3i8(i8 addrspace(3)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f32_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.f32.p3i8(i8 addrspace(3)* %src );
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f32.p3i8(i8 addrspace(3)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f32_p3i8(i8 addrspace(3)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f32_p3i8(
; CHECK-SAME: ptr addrspace(3) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f32.p3i8(i8 addrspace(3)* %src , i32 %stride);
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.f32.p1i8(i8 addrspace(1)* %src );

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f32_p1i8(i8 addrspace(1)* %src ) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_f32_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.f32.p1i8(i8 addrspace(1)* %src );
  ret void;
}


declare {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f32.p1i8(i8 addrspace(1)* %src , i32 %stride);

define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f32_p1i8(i8 addrspace(1)* %src , i32 %stride) {
; CHECK-LABEL: define void @test_llvm_nvvm_wmma_m16n16k16_load_c_col_stride_f32_p1i8(
; CHECK-SAME: ptr addrspace(1) [[SRC:%.*]], i32 [[STRIDE:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call {float, float, float, float, float, float, float, float} @llvm.nvvm.wmma.m16n16k16.load.c.col.stride.f32.p1i8(i8 addrspace(1)* %src , i32 %stride);
  ret void;
}

; SystemZ

declare <16 x i8> @llvm.s390.vlbb(ptr, i32)
declare <16 x i8> @llvm.s390.vll(i32, ptr)
declare <16 x i8> @llvm.s390.vlrl(i32, ptr)

define void @test_llvm_s390.vlbb(ptr %a) {
; CHECK-LABEL: define void @test_llvm_s390.vlbb(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <16 x i8> @llvm.s390.vlbb(ptr %a, i32 8)
  ret void
}

define void @test_llvm_s390.vll(i32 %a, ptr %b) {
; CHECK-LABEL: define void @test_llvm_s390.vll(
; CHECK-SAME: i32 [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <16 x i8> @llvm.s390.vll(i32 %a, ptr %b)
  ret void
}

define void @test_llvm_s390.vlrl(i32 %a, ptr %b) {
; CHECK-LABEL: define void @test_llvm_s390.vlrl(
; CHECK-SAME: i32 [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <16 x i8> @llvm.s390.vlrl(i32 %a, ptr %b)
  ret void
}

; VE

declare i64 @llvm.ve.vl.pack.f32p(ptr, ptr)

define void @test_llvm_ve_vl_pack_f32p(ptr %a, ptr %b) {
; CHECK-LABEL: define void @test_llvm_ve_vl_pack_f32p(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call i64 @llvm.ve.vl.pack.f32p(ptr %a, ptr %b)
  ret void
}


declare i64 @llvm.ve.vl.pack.f32a(ptr)

define void @test_llvm_ve_vl_pack_f32a(ptr %a) {
; CHECK-LABEL: define void @test_llvm_ve_vl_pack_f32a(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call i64 @llvm.ve.vl.pack.f32a(ptr %a)
  ret void
}

declare <256 x double> @llvm.ve.vl.vld.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vld_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vld_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vld.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vld.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vld_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vld_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vld.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldnc.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldnc_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldnc_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldnc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldnc.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldnc_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldnc_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldnc.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldu.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldu_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldu_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldu.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldu.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldu_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldu_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldu.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldunc.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldunc_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldunc_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldunc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldunc.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldunc_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldunc_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldunc.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldlsx.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldlsx_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldlsx_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldlsx.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldlsx.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldlsx_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldlsx_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldlsx.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldlsxnc.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldlsxnc_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldlsxnc_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldlsxnc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldlsxnc.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldlsxnc_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldlsxnc_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldlsxnc.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldlzx.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldlzx_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldlzx_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldlzx.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldlzx.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldlzx_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldlzx_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldlzx.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldlzxnc.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldlzxnc_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldlzxnc_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldlzxnc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldlzxnc.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldlzxnc_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldlzxnc_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldlzxnc.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vld2d.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vld2d_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vld2d_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vld2d.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vld2d.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vld2d_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vld2d_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vld2d.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vld2dnc.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vld2dnc_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vld2dnc_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vld2dnc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vld2dnc.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vld2dnc_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vld2dnc_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vld2dnc.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldu2d.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldu2d_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldu2d_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldu2d.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldu2d.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldu2d_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldu2d_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldu2d.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldu2dnc.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldu2dnc_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldu2dnc_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldu2dnc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldu2dnc.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldu2dnc_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldu2dnc_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldu2dnc.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldl2dsx.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldl2dsx_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldl2dsx_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldl2dsx.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldl2dsx.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldl2dsx_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldl2dsx_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldl2dsx.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldl2dsxnc.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldl2dsxnc_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldl2dsxnc_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldl2dsxnc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldl2dsxnc.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldl2dsxnc_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldl2dsxnc_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldl2dsxnc.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldl2dzx.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldl2dzx_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldl2dzx_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldl2dsxnc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldl2dzx.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldl2dzx_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldl2dzx_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldl2dzx.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldl2dzxnc.vssl(i64, ptr, i32)

define void @test_llvm_ve_vl_vldl2dzxnc_vssl(i64 %a, ptr %b, i32 %c) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldl2dzxnc_vssl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], i32 [[C:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldl2dzxnc.vssl(i64 %a, ptr %b, i32 %c)
  ret void
}

declare <256 x double> @llvm.ve.vl.vldl2dzxnc.vssvl(i64, ptr, <256 x double>, i32)

define void @test_llvm_ve_vl_vldl2dzxnc_vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vldl2dzxnc_vssvl(
; CHECK-SAME: i64 [[A:%.*]], ptr [[B:%.*]], <256 x double> [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vldl2dzxnc.vssvl(i64 %a, ptr %b, <256 x double> %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgt.vvssl(<256 x double>, i64, i64, i32)

define void @test_llvm_ve_vl_vgt_vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgt_vvssl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgt.vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgt.vvssvl(<256 x double>, i64, i64, <256 x double>, i32)

define void @test_llvm_ve_vl_vgt_vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgt_vvssvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x double> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgt.vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgt.vvssml(<256 x double>, i64, i64, <256 x i1>, i32)

define void @test_llvm_ve_vl_vgt_vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgt_vvssml(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgt.vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgt.vvssmvl(<256 x double>, i64, i64, <256 x i1>, <256 x double>, i32)

define void @test_llvm_ve_vl_vgt_vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgt_vvssmvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], <256 x double> [[E:%.*]], i32 [[F:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgt.vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtnc.vvssl(<256 x double>, i64, i64, i32)

define void @test_llvm_ve_vl_vgtnc_vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtnc_vvssl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtnc.vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtnc.vvssvl(<256 x double>, i64, i64, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtnc_vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtnc_vvssvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x double> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtnc.vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtnc.vvssml(<256 x double>, i64, i64, <256 x i1>, i32)

define void @test_llvm_ve_vl_vgtnc_vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtnc_vvssml(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtnc.vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtnc.vvssmvl(<256 x double>, i64, i64, <256 x i1>, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtnc_vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtnc_vvssmvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], <256 x double> [[E:%.*]], i32 [[F:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtnc.vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtu.vvssl(<256 x double>, i64, i64, i32)

define void @test_llvm_ve_vl_vgtu_vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtu_vvssl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtu.vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtu.vvssvl(<256 x double>, i64, i64, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtu_vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtu_vvssvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x double> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtu.vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtu.vvssml(<256 x double>, i64, i64, <256 x i1>, i32)

define void @test_llvm_ve_vl_vgtu_vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtu_vvssml(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtu.vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtu.vvssmvl(<256 x double>, i64, i64, <256 x i1>, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtu_vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtu_vvssmvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], <256 x double> [[E:%.*]], i32 [[F:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtu.vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtunc.vvssl(<256 x double>, i64, i64, i32)

define void @test_llvm_ve_vl_vgtunc_vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtunc_vvssl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtunc.vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtunc.vvssvl(<256 x double>, i64, i64, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtunc_vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtunc_vvssvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x double> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtunc.vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtunc.vvssml(<256 x double>, i64, i64, <256 x i1>, i32)

define void @test_llvm_ve_vl_vgtunc_vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtunc_vvssml(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtunc.vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtunc.vvssmvl(<256 x double>, i64, i64, <256 x i1>, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtunc_vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtunc_vvssmvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], <256 x double> [[E:%.*]], i32 [[F:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtunc.vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlsx.vvssl(<256 x double>, i64, i64, i32)

define void @test_llvm_ve_vl_vgtlsx_vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlsx_vvssl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlsx.vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlsx.vvssvl(<256 x double>, i64, i64, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtlsx_vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlsx_vvssvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x double> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlsx.vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlsx.vvssml(<256 x double>, i64, i64, <256 x i1>, i32)

define void @test_llvm_ve_vl_vgtlsx_vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlsx_vvssml(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlsx.vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlsx.vvssmvl(<256 x double>, i64, i64, <256 x i1>, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtlsx_vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlsx_vvssmvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], <256 x double> [[E:%.*]], i32 [[F:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlsx.vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlsxnc.vvssl(<256 x double>, i64, i64, i32)

define void @test_llvm_ve_vl_vgtlsxnc_vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlsxnc_vvssl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlsxnc.vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlsxnc.vvssvl(<256 x double>, i64, i64, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtlsxnc_vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlsxnc_vvssvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x double> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlsxnc.vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlsxnc.vvssml(<256 x double>, i64, i64, <256 x i1>, i32)

define void @test_llvm_ve_vl_vgtlsxnc_vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlsxnc_vvssml(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlsxnc.vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlsxnc.vvssmvl(<256 x double>, i64, i64, <256 x i1>, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtlsxnc_vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlsxnc_vvssmvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], <256 x double> [[E:%.*]], i32 [[F:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlsxnc.vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlzx.vvssl(<256 x double>, i64, i64, i32)

define void @test_llvm_ve_vl_vgtlzx_vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlzx_vvssl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlzx.vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlzx.vvssvl(<256 x double>, i64, i64, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtlzx_vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlzx_vvssvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x double> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlzx.vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlzx.vvssml(<256 x double>, i64, i64, <256 x i1>, i32)

define void @test_llvm_ve_vl_vgtlzx_vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlzx_vvssml(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlzx.vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlzx.vvssmvl(<256 x double>, i64, i64, <256 x i1>, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtlzx_vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlzx_vvssmvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], <256 x double> [[E:%.*]], i32 [[F:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlzx.vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlzxnc.vvssl(<256 x double>, i64, i64, i32)

define void @test_llvm_ve_vl_vgtlzxnc_vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlzxnc_vvssl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], i32 [[D:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlzxnc.vvssl(<256 x double> %a, i64 %b, i64 %c, i32 %d)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlzxnc.vvssvl(<256 x double>, i64, i64, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtlzxnc_vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlzxnc_vvssvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x double> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlzxnc.vvssvl(<256 x double> %a, i64 %b, i64 %c, <256 x double> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlzxnc.vvssml(<256 x double>, i64, i64, <256 x i1>, i32)

define void @test_llvm_ve_vl_vgtlzxnc_vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlzxnc_vvssml(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], i32 [[E:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlzxnc.vvssml(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, i32 %e)
  ret void
}

declare <256 x double> @llvm.ve.vl.vgtlzxnc.vvssmvl(<256 x double>, i64, i64, <256 x i1>, <256 x double>, i32)

define void @test_llvm_ve_vl_vgtlzxnc_vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f) {
; CHECK-LABEL: define void @test_llvm_ve_vl_vgtlzxnc_vvssmvl(
; CHECK-SAME: <256 x double> [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]], <256 x i1> [[D:%.*]], <256 x double> [[E:%.*]], i32 [[F:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call <256 x double> @llvm.ve.vl.vgtlzxnc.vvssmvl(<256 x double> %a, i64 %b, i64 %c, <256 x i1> %d, <256 x double> %e, i32 %f)
  ret void
}

; WebAssembly

declare float @llvm.wasm.loadf16.f32(ptr)

define void @test_llvm_wasm_loadf16_f32(ptr %a) {
; CHECK-LABEL: define void @test_llvm_wasm_loadf16_f32(
; CHECK-SAME: ptr [[A:%.*]]) {
; CHECK-NEXT:    ret void
;
  %v = call float @llvm.wasm.loadf16.f32(ptr %a)
  ret void
}



